# HyperCLOVAX ν•κµ­μ–΄ ν…μ¤νΈ λΉ„λ‚λ…ν™” νμΈνλ‹

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![Transformers](https://img.shields.io/badge/π¤—%20Transformers-Latest-yellow.svg)](https://huggingface.co/transformers)

μ΄ ν”„λ΅μ νΈλ” Naverμ HyperCLOVAX-SEED-Text-Instruct-0.5B λ¨λΈμ„ ν•κµ­μ–΄ ν…μ¤νΈ λΉ„λ‚λ…ν™”λ¥Ό μ„ν•΄ LoRA(Low-Rank Adaptation)λ¥Ό μ‚¬μ©ν•μ—¬ ν¨μ¨μ μΌλ΅ νμΈνλ‹ν•λ” λ°©λ²•μ„ λ³΄μ—¬μ¤λ‹λ‹¤.

## π― ν”„λ΅μ νΈ κ°μ”

μ΄ ν”„λ΅μ νΈμ λ©ν‘λ” λ‚λ…ν™”λ ν•κµ­μ–΄ ν…μ¤νΈλ¥Ό μ›λ³Έ ν•νƒλ΅ λ³µμ›ν•  μ μλ” λ¨λΈμ„ ν›λ ¨μ‹ν‚¤λ” κ²ƒμ…λ‹λ‹¤. λ‹¤μκ³Ό κ°™μ€ λ‹¤μ–‘ν• μ ν•μ ν•κµ­μ–΄ ν…μ¤νΈλ΅ ν›λ ¨λ©λ‹λ‹¤:

- **κµ¬μ–΄μ²΄ (κµ¬μ–΄μ²΄)** - 16,878κ° μƒν”
- **λ‰΄μ¤λ¬Έμ–΄μ²΄ (λ‰΄μ¤ ν…μ¤νΈ)** - 281,932κ° μƒν”  
- **λ¬Έν™”λ¬Έμ–΄μ²΄ (λ¬Έν™” ν…μ¤νΈ)** - 25,628κ° μƒν”
- **μ „λ¬Έλ¶„μ•Όλ¬Έμ–΄μ²΄ (μ „λ¬Έ κΈ°μ  ν…μ¤νΈ)** - 306,542κ° μƒν”
- **μ΅°λ΅€λ¬Έμ–΄μ²΄ (λ²•λ Ή ν…μ¤νΈ)** - 36,339κ° μƒν”
- **μ§€μμ²΄μ›Ήμ‚¬μ΄νΈλ¬Έμ–΄μ²΄ (μ§€μμ²΄ μ›Ήμ‚¬μ΄νΈ ν…μ¤νΈ)** - 28,705κ° μƒν”

## π€ μ£Όμ” κΈ°λ¥

- **ν¨μ¨μ μΈ νμΈνλ‹**: λ©”λ¨λ¦¬ ν¨μ¨μ μΈ ν›λ ¨μ„ μ„ν• LoRA(Low-Rank Adaptation) μ‚¬μ©
- **4λΉ„νΈ μ–‘μν™”**: λ©”λ¨λ¦¬ μ‚¬μ©λ‰ κ°μ†λ¥Ό μ„ν• BitsAndBytesConfig κµ¬ν„
- **λ‹¤μ¤‘ μΉ΄ν…κ³ λ¦¬ μ§€μ›**: λ‹¤μ–‘ν• ν•κµ­μ–΄ ν…μ¤νΈ μ ν• μ²λ¦¬
- **μΈν„°λ™ν‹°λΈ λ°λ¨**: μ‹¤μ‹κ°„ λΉ„λ‚λ…ν™”λ¥Ό μ„ν• Gradio μΈν„°νμ΄μ¤
- **μΆ…ν•©μ μΈ ν‰κ°€**: BLEU λ° ROUGE μ μ λ©”νΈλ¦­
- **GPU μµμ ν™”**: μλ™ λ””λ°”μ΄μ¤ λ§¤ν•‘μ„ ν†µν• CUDA μ§€μ›

## π“‹ μ”κµ¬μ‚¬ν•­

### ν•λ“μ›¨μ–΄ μ”κµ¬μ‚¬ν•­
- **GPU**: CUDA μ§€μ› NVIDIA GPU (κ¶μ¥: 16GB+ VRAM)
- **λ©”λ¨λ¦¬**: λ€μ©λ‰ λ°μ΄ν„°μ…‹μ„ μ„ν•΄ 32GB+ RAM κ¶μ¥
- **μ €μ¥κ³µκ°„**: λ¨λΈ λ° λ°μ΄ν„°μ…‹μ„ μ„ν• 50GB+ μ—¬μ  κ³µκ°„

### μ†ν”„νΈμ›¨μ–΄ μ”κµ¬μ‚¬ν•­
- Python 3.8+
- CUDA 11.8+ (GPU κ°€μ†μ„ μ„ν•΄)
- μƒμ„Έν• ν¨ν‚¤μ§€ μμ΅΄μ„±μ€ `requirements.txt` μ°Έμ΅°

### μ£Όμ” μμ΅΄μ„±
```
transformers
peft
trl
datasets
bitsandbytes
accelerate
torch>=2.0.0
gradio
evaluate
rouge-score
sentencepiece
protobuf
scikit-learn
pandas
numpy
```

## π› οΈ μ„¤μΉ

1. **μ €μ¥μ† ν΄λ΅ **:
```bash
git clone <repository-url>
cd FineTuningLLM
```

2. **κ°€μƒν™κ²½ μƒμ„±**:
```bash
python -m venv venv
source venv/bin/activate  # Windowsμ κ²½μ°: venv\Scripts\activate
```

3. **μμ΅΄μ„± μ„¤μΉ**:
```bash
pip install transformers peft trl datasets bitsandbytes accelerate evaluate rouge-score sentencepiece protobuf gradio scikit-learn pandas numpy torch
```

4. **CUDA μ„¤μΉ ν™•μΈ** (μ„ νƒμ‚¬ν•­):
```bash
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

## π“ λ°μ΄ν„°μ…‹ κµ¬μ΅°

ν”„λ΅μ νΈλ” λ‚λ…ν™”λ ν•κµ­μ–΄ ν…μ¤νΈμ™€ μ›λ³Έ ν…μ¤νΈκ°€ ν¬ν•¨λ CSV νμΌμ„ μ‚¬μ©ν•©λ‹λ‹¤:

```
λ°μ΄ν„°μ…‹ νμΌ:
β”β”€β”€ κµ¬μ–΄μ²΄_λ€ν™”μ²΄_16878_sample_λ‚λ…ν™”κ²°κ³Ό.csv
β”β”€β”€ λ‰΄μ¤λ¬Έμ–΄μ²΄_281932_sample_λ‚λ…ν™”κ²°κ³Ό.csv
β”β”€β”€ λ¬Έν™”λ¬Έμ–΄μ²΄_25628_sample_λ‚λ…ν™”κ²°κ³Ό.csv
β”β”€β”€ μ „λ¬Έλ¶„μ•Ό λ¬Έμ–΄μ²΄_306542_sample_λ‚λ…ν™”κ²°κ³Ό.csv
β”β”€β”€ μ΅°λ΅€λ¬Έμ–΄μ²΄_36339_sample_λ‚λ…ν™”κ²°κ³Ό.csv
β””β”€β”€ μ§€μμ²΄μ›Ήμ‚¬μ΄νΈ λ¬Έμ–΄μ²΄_28705_sample_λ‚λ…ν™”κ²°κ³Ό.csv
```

κ° CSV νμΌμ κµ¬μ„±:
- `obfuscated`: λ‚λ…ν™”λ ν•κµ­μ–΄ ν…μ¤νΈ
- `original`: μ›λ³Έ ν•κµ­μ–΄ ν…μ¤νΈ
- μ¶”κ°€ λ©”νƒ€λ°μ΄ν„° μ»¬λΌλ“¤

### λ΅μ»¬ νμΌ κ²½λ΅ μ„¤μ •

λ…ΈνΈλ¶μ„ λ΅μ»¬μ—μ„ μ‹¤ν–‰ν•  λ•λ” λ‹¤μκ³Ό κ°™μ΄ νμΌ κ²½λ΅λ¥Ό μμ •ν•μ„Έμ”:

```python
# λ΅μ»¬ μ‹¤ν–‰μ© νμΌ κ²½λ΅
data_files = {
    'κµ¬μ–΄μ²΄_λ€ν™”μ²΄': './κµ¬μ–΄μ²΄_λ€ν™”μ²΄_16878_sample_λ‚λ…ν™”κ²°κ³Ό.csv',
    'λ‰΄μ¤λ¬Έμ–΄μ²΄': './λ‰΄μ¤λ¬Έμ–΄μ²΄_281932_sample_λ‚λ…ν™”κ²°κ³Ό.csv',
    'λ¬Έν™”λ¬Έμ–΄μ²΄': './λ¬Έν™”λ¬Έμ–΄μ²΄_25628_sample_λ‚λ…ν™”κ²°κ³Ό.csv',
    'μ „λ¬Έλ¶„μ•Όλ¬Έμ–΄μ²΄': './μ „λ¬Έλ¶„μ•Ό λ¬Έμ–΄μ²΄_306542_sample_λ‚λ…ν™”κ²°κ³Ό.csv',
    'μ΅°λ΅€λ¬Έμ–΄μ²΄': './μ΅°λ΅€λ¬Έμ–΄μ²΄_36339_sample_λ‚λ…ν™”κ²°κ³Ό.csv',
    'μ§€μμ²΄μ›Ήμ‚¬μ΄νΈλ¬Έμ–΄μ²΄': './μ§€μμ²΄μ›Ήμ‚¬μ΄νΈ λ¬Έμ–΄μ²΄_28705_sample_λ‚λ…ν™”κ²°κ³Ό.csv'
}
```

## πƒβ€β™‚οΈ λΉ λ¥Έ μ‹μ‘

### λ…ΈνΈλ¶ μ‹¤ν–‰

1. **Jupyter Notebook μ‹¤ν–‰**:
```bash
jupyter notebook hyperclova_deobfuscation_finetuning.ipynb
```

2. **λλ” Jupyter Lab μ‚¬μ©**:
```bash
jupyter lab hyperclova_deobfuscation_finetuning.ipynb
```

3. **Google Colab μ‚¬μ©**:
   - λ…ΈνΈλ¶μ„ Google Colabμ— μ—…λ΅λ“
   - λ°μ΄ν„°μ…‹ μ ‘κ·Όμ„ μ„ν•΄ Google Drive λ§μ΄νΈ
   - λ…ΈνΈλ¶μ λ°μ΄ν„° λ΅λ”© μ„Ήμ…μ—μ„ νμΌ κ²½λ΅ μ„¤μ •

### ν›λ ¨λ λ¨λΈ μ‚¬μ©

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import torch

# λ² μ΄μ¤ λ¨λΈ λ΅λ“
base_model = AutoModelForCausalLM.from_pretrained(
    "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B"
)

# νμΈνλ‹λ LoRA μ–΄λ‘ν„° λ΅λ“
model = PeftModel.from_pretrained(base_model, "./hyperclova-deobfuscation-lora")
tokenizer = AutoTokenizer.from_pretrained("./hyperclova-deobfuscation-lora")

def deobfuscate_text(obfuscated_text):
    prompt = f"### μ§€μ‹μ‚¬ν•­:\nλ‹¤μ λ‚λ…ν™”λ ν•κµ­μ–΄ ν…μ¤νΈλ¥Ό μ›λ ν…μ¤νΈλ΅ λ³µμ›ν•΄μ£Όμ„Έμ”.\n\nλ‚λ…ν™”λ ν…μ¤νΈ: {obfuscated_text}\n\n### μ‘λ‹µ:\n"
    
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=256,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            pad_token_id=tokenizer.eos_token_id
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response.split("### μ‘λ‹µ:")[1].strip()

# μ‚¬μ© μμ‹
obfuscated = "μ•λ…€ν•μΌμ”, λ°κ°‘μλ‹λ!"
original = deobfuscate_text(obfuscated)
print(f"λ³µμ›λ ν…μ¤νΈ: {original}")
```

## π”§ λ¨λΈ μ„¤μ •

### λ°μ΄ν„° μ „μ²λ¦¬
λ…ΈνΈλ¶μ—μ„λ” λ©”λ¨λ¦¬ ν¨μ¨μ„±μ„ μ„ν•΄ 10,000κ° μƒν”λ΅ μ ν•ν•μ—¬ ν›λ ¨ν•©λ‹λ‹¤:

```python
# λ©”λ¨λ¦¬ μ μ•½μ„ μ„ν• μƒν” ν¬κΈ° μ΅°μ •
sample_size = 10000  # ν•„μ”μ— λ”°λΌ μ΅°μ • κ°€λ¥
instruction_df = create_instruction_dataset(combined_df, sample_size)
```

### LoRA μ„¤μ •
```python
lora_config = LoraConfig(
    r=16,                    # λ­ν¬
    lora_alpha=32,          # μ¤μΌ€μΌλ§ νλΌλ―Έν„°
    target_modules=[        # νƒ€κ² μ–΄ν…μ… λ μ΄μ–΄
        "q_proj", "k_proj", "v_proj", "o_proj", 
        "gate_proj", "up_proj", "down_proj"
    ],
    lora_dropout=0.1,
    bias="none",
    task_type=TaskType.CAUSAL_LM
)
```

### ν›λ ¨ μ„¤μ •
```python
training_args = TrainingArguments(
    output_dir="./hyperclova-deobfuscation-lora",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    weight_decay=0.01,
    fp16=True,
    eval_strategy="steps",  # μ—…λ°μ΄νΈλ νλΌλ―Έν„°λ…
    eval_steps=200,
    save_steps=200,
    logging_steps=10
)
```

## π“ μ„±λ¥ λ©”νΈλ¦­

λ¨λΈμ€ λ‹¤μκ³Ό κ°™μ€ μ—¬λ¬ λ©”νΈλ¦­μΌλ΅ ν‰κ°€λ©λ‹λ‹¤:

- **BLEU Score**: μμΈ΅λ ν…μ¤νΈμ™€ μ°Έμ΅° ν…μ¤νΈ κ°„μ n-gram κ²ΉμΉ¨ μΈ΅μ •
- **ROUGE-1/2/L**: ν…μ¤νΈ μ”μ•½μ„ μ„ν• recall μ§€ν–¥μ  μ΄ν•΄λ„ ν‰κ°€
- **μ •μ„±μ  λ¶„μ„**: λΉ„λ‚λ…ν™” ν’μ§μ μλ™ κ²€μ‚¬

### ν‰κ°€ μμ‹
λ…ΈνΈλ¶μ—λ” 100κ° μƒν”μ— λ€ν• μ •λ‰μ  ν‰κ°€κ°€ ν¬ν•¨λμ–΄ μμµλ‹λ‹¤:

```python
# 100κ° μƒν”λ΅ ν‰κ°€
eval_samples = val_df.sample(n=100, random_state=42)
# BLEU, ROUGE μ¤μ½”μ–΄ κ³„μ‚°
metrics = calculate_metrics(predictions, references)
```

### μμ‹ κ²°κ³Ό
```
BLEU Score: 0.xxxx
ROUGE-1: 0.xxxx
ROUGE-2: 0.xxxx
ROUGE-L: 0.xxxx
```

## π® μΈν„°λ™ν‹°λΈ λ°λ¨

λ…ΈνΈλ¶μ—λ” μ‹¤μ‹κ°„ ν…μ¤νΈ λΉ„λ‚λ…ν™”λ¥Ό μ„ν• Gradio κΈ°λ° μ›Ή μΈν„°νμ΄μ¤κ°€ ν¬ν•¨λμ–΄ μμµλ‹λ‹¤:

```python
import gradio as gr

demo = gr.Interface(
    fn=deobfuscate_interface,
    inputs=gr.Textbox(label="λ‚λ…ν™”λ ν•κµ­μ–΄ ν…μ¤νΈ"),
    outputs=gr.Textbox(label="λ³µμ›λ μ›λ³Έ ν…μ¤νΈ"),
    title="HyperCLOVAX ν•κµ­μ–΄ ν…μ¤νΈ λΉ„λ‚λ…ν™”",
    examples=[
        ["μ•λ…€ν•μΌμ”, λ°κ°‘μλ‹λ!"],
        ["μ¤λ¬ λ‚ μ”¨κ°Έ λ§†μ΄ μΆ†λ„¤μ."],
        ["ν•νΏμ–΄ μ³¬μ—°μ–΄ μ²λ¥„μ λ•ν–” μ—°κ·μ„ ν•΄λ³΄κ°°μµλ‹λ."]
    ]
)

demo.launch(share=True)
```

## π ν™κ²½ νΈν™μ„±

### Google Colab
λ…ΈνΈλ¶μ€ Google Colabμ—μ„ μ‹¤ν–‰λλ„λ΅ μµμ ν™”λμ–΄ μμµλ‹λ‹¤:
- Google Drive λ§μ΄νΈ μ§€μ›
- GPU λ©”λ¨λ¦¬ μµμ ν™”
- μλ™ ν¨ν‚¤μ§€ μ„¤μΉ

### λ΅μ»¬ ν™κ²½
λ΅μ»¬μ—μ„ μ‹¤ν–‰ν•λ ¤λ©΄:
1. Google Colab κ΄€λ ¨ μ½”λ“ μ£Όμ„ μ²λ¦¬
2. λ°μ΄ν„° νμΌ κ²½λ΅λ¥Ό λ΅μ»¬ κ²½λ΅λ΅ μμ •
3. ν•„μ”ν• ν¨ν‚¤μ§€ μ‚¬μ „ μ„¤μΉ

## π“ ν”„λ΅μ νΈ κµ¬μ΅°

```
FineTuningLLM/
β”β”€β”€ .github/
β”‚   β””β”€β”€ README.md                           # μ΄ νμΌ
β”β”€β”€ hyperclova_deobfuscation_finetuning.ipynb  # λ©”μΈ λ…ΈνΈλ¶
β”β”€β”€ LICENSE                                # ν”„λ΅μ νΈ λΌμ΄μ„ μ¤
β”β”€β”€ κµ¬μ–΄μ²΄_λ€ν™”μ²΄_16878_sample_λ‚λ…ν™”κ²°κ³Ό.csv      # κµ¬μ–΄μ²΄ λ°μ΄ν„°μ…‹
β”β”€β”€ λ‰΄μ¤λ¬Έμ–΄μ²΄_281932_sample_λ‚λ…ν™”κ²°κ³Ό.csv        # λ‰΄μ¤ λ°μ΄ν„°μ…‹
β”β”€β”€ λ¬Έν™”λ¬Έμ–΄μ²΄_25628_sample_λ‚λ…ν™”κ²°κ³Ό.csv         # λ¬Έν™” λ°μ΄ν„°μ…‹
β”β”€β”€ μ „λ¬Έλ¶„μ•Ό λ¬Έμ–΄μ²΄_306542_sample_λ‚λ…ν™”κ²°κ³Ό.csv    # μ „λ¬Έλ¶„μ•Ό λ°μ΄ν„°μ…‹
β”β”€β”€ μ΅°λ΅€λ¬Έμ–΄μ²΄_36339_sample_λ‚λ…ν™”κ²°κ³Ό.csv         # μ΅°λ΅€ λ°μ΄ν„°μ…‹
β””β”€β”€ μ§€μμ²΄μ›Ήμ‚¬μ΄νΈ λ¬Έμ–΄μ²΄_28705_sample_λ‚λ…ν™”κ²°κ³Ό.csv # μ§€μμ²΄ μ›Ήμ‚¬μ΄νΈ λ°μ΄ν„°μ…‹
```

## β™οΈ μ‹¤ν–‰ μ‹ μ£Όμμ‚¬ν•­

### λ©”λ¨λ¦¬ μµμ ν™”
- λ…ΈνΈλ¶μ—μ„λ” `sample_size=10000`μΌλ΅ μ ν•ν•μ—¬ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μ μ•½
- λ” λ§μ€ λ°μ΄ν„° μ‚¬μ© μ‹ GPU λ©”λ¨λ¦¬μ™€ RAM μ©λ‰ ν™•μΈ ν•„μ”
- 4λΉ„νΈ μ–‘μν™”(`BitsAndBytesConfig`) μ‚¬μ©μΌλ΅ λ©”λ¨λ¦¬ ν¨μ¨μ„± ν–¥μƒ

### νμΌ κ²½λ΅ μ„¤μ •
**Google Colab μ‚¬μ© μ‹:**
```python
# Google Drive κ²½λ΅ (λ…ΈνΈλ¶ κΈ°λ³Έκ°’)
'/content/drive/MyDrive/νμΌλ….csv'
```

**λ΅μ»¬ μ‹¤ν–‰ μ‹:**
```python
# λ΅μ»¬ κ²½λ΅λ΅ μμ • ν•„μ”
'./νμΌλ….csv'
```

### GPU μ”κµ¬μ‚¬ν•­
- NVIDIA GPU κ¶μ¥ (8GB+ VRAM)
- CUDA 11.8+ μ„¤μΉ ν•„μ”
- CPUλ§μΌλ΅λ„ μ‹¤ν–‰ κ°€λ¥ν•μ§€λ§ μ†λ„ ν„μ €ν μ €ν•

## π¤ κΈ°μ—¬ν•κΈ°

κΈ°μ—¬λ” μ–Έμ λ‚ ν™μν•©λ‹λ‹¤! Pull Requestλ¥Ό μμ λ΅­κ² μ μ¶ν•΄ μ£Όμ„Έμ”. μ£Όμ” λ³€κ²½μ‚¬ν•­μ κ²½μ°, λ¨Όμ € issueλ¥Ό μ—΄μ–΄ λ…Όμν•΄ μ£Όμ‹κΈ° λ°”λλ‹λ‹¤.

### κ°λ° ν™κ²½ μ„¤μ •
1. μ €μ¥μ† ν¬ν¬
2. κΈ°λ¥ λΈλμΉ μƒμ„± (`git checkout -b feature/amazing-feature`)
3. λ³€κ²½μ‚¬ν•­ μ»¤λ°‹ (`git commit -m 'Add some amazing feature'`)
4. λΈλμΉμ— ν‘Έμ‹ (`git push origin feature/amazing-feature`)
5. Pull Request μ—΄κΈ°

## π“„ λΌμ΄μ„ μ¤

μ΄ ν”„λ΅μ νΈλ” MIT λΌμ΄μ„ μ¤ ν•μ— μμµλ‹λ‹¤ - μμ„Έν• λ‚΄μ©μ€ [LICENSE](../LICENSE) νμΌμ„ μ°Έμ΅°ν•μ„Έμ”.

## π™ κ°μ‚¬μ λ§

- **Naver AI**: HyperCLOVAX-SEED-Text-Instruct-0.5B λ² μ΄μ¤ λ¨λΈ μ κ³µ
- **Hugging Face**: transformers λΌμ΄λΈλ¬λ¦¬μ™€ λ¨λΈ νΈμ¤ν…
- **Microsoft**: PEFT λΌμ΄λΈλ¬λ¦¬μ LoRA κµ¬ν„
- **ν•κµ­μ–΄ NLP μ»¤λ®¤λ‹ν‹°**: λ°μ΄ν„°μ…‹ κΈ°μ—¬ λ° μ—°κµ¬

## π“ μ§€μ›

λ¬Έμ κ°€ λ°μƒν•κ±°λ‚ μ§λ¬Έμ΄ μμΌμ‹λ©΄:

1. κΈ°μ΅΄ ν•΄κ²°μ±…μ„ μ„ν•΄ [Issues](../../issues) νμ΄μ§€ ν™•μΈ
2. λ¬Έμ μ— λ€ν• μμ„Έν• μ •λ³΄μ™€ ν•¨κ» μƒ issue μƒμ„±
3. λ²„κ·Έ μ‹ κ³  μ‹ μ‹μ¤ν… μ‚¬μ–‘κ³Ό μ¤λ¥ λ΅κ·Έ ν¬ν•¨

## π”— κ΄€λ ¨ μλ£

- [HyperCLOVAX λ¨λΈ μΉ΄λ“](https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B)
- [LoRA λ…Όλ¬Έ](https://arxiv.org/abs/2106.09685)
- [Parameter-Efficient Fine-Tuning](https://huggingface.co/docs/peft)
- [ν•κµ­μ–΄ μ–Έμ–΄μ²λ¦¬ μλ£](https://github.com/topics/korean-nlp)

---

**μ°Έκ³ **: μ΄ ν”„λ΅μ νΈλ” μ—°κµ¬ λ° κµμ΅ λ©μ μ…λ‹λ‹¤. μ΄ μ½”λ“λ¥Ό μ‚¬μ©ν•  λ• λ¨λΈ μ‚¬μ© μ•½κ΄€ λ° λ°μ΄ν„° κ°μΈμ •λ³΄λ³΄νΈ κ·μ •μ„ μ¤€μν•μ‹κΈ° λ°”λλ‹λ‹¤.
