{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bbf116",
   "metadata": {},
   "source": [
    "# HyperCLOVAX ëª¨ë¸ Learning Rate ë¹„êµ ë¶„ì„\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì›ë³¸ ëª¨ë¸ê³¼ ì„œë¡œ ë‹¤ë¥¸ learning rateë¡œ ë¯¸ì„¸ì¡°ì •ëœ HyperCLOVAX ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ë¶„ì„ ëª©í‘œ\n",
    "- ì„¸ ëª¨ë¸ ê°„ ì •ëŸ‰ì  ì„±ëŠ¥ ë¹„êµ (BLEU, ROUGE, ë¬¸ì ì •í™•ë„)\n",
    "- ì •ì„±ì  ë¶„ì„ (ì‹¤ì œ ì¶œë ¥ ì˜ˆì‹œ ë¹„êµ)\n",
    "- ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¶„ì„\n",
    "- ì¶”ë¡  ì‹œê°„ ë° íš¨ìœ¨ì„± ë¹„êµ\n",
    "- Learning Rate ë¯¸ì„¸ì¡°ì • íš¨ê³¼ ë¶„ì„\n",
    "- ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "## ëª¨ë¸ ì •ë³´\n",
    "- **ì›ë³¸ ëª¨ë¸**: `naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B`\n",
    "- **1e-4 Learning Rate ëª¨ë¸**: `hyperclova-deobfuscation-lora-1e-4-learning-rate`\n",
    "- **5e-4 Learning Rate ëª¨ë¸**: `hyperclova-deobfuscation-lora-5e-4-learning-rate`\n",
    "- **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: `testdata.csv` (1,002 ìƒ˜í”Œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb29ec6",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bdfbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU í™•ì¸\n",
    "!nvidia-smi\n",
    "\n",
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install -q transformers\n",
    "!pip install -q peft\n",
    "!pip install -q torch\n",
    "!pip install -q datasets\n",
    "!pip install -q evaluate\n",
    "!pip install -q rouge-score\n",
    "!pip install -q sacrebleu\n",
    "!pip install -q sentencepiece\n",
    "!pip install -q protobuf\n",
    "!pip install -q matplotlib\n",
    "!pip install -q seaborn\n",
    "!pip install -q plotly\n",
    "!pip install -q pandas\n",
    "!pip install -q numpy\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q tqdm\n",
    "\n",
    "print(\"íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58dc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib ë° seaborn ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±\n",
    "image_save_dir = '/content/drive/MyDrive/Colab Notebooks/analysis_images'\n",
    "os.makedirs(image_save_dir, exist_ok=True)\n",
    "print(f\"ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±: {image_save_dir}\")\n",
    "\n",
    "# ì¥ì¹˜ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5b03f",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96487bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive ì—°ê²° (Colabì—ì„œ ì‹¤í–‰ ì‹œ)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    import shutil\n",
    "    \n",
    "    # ê¸°ì¡´ ë§ˆìš´íŠ¸ í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ ì •ë¦¬\n",
    "    mount_point = '/content/drive'\n",
    "    if os.path.exists(mount_point):\n",
    "        try:\n",
    "            # ë§ˆìš´íŠ¸ í•´ì œ ì‹œë„\n",
    "            print(\"ê¸°ì¡´ ë§ˆìš´íŠ¸ í¬ì¸íŠ¸ ì •ë¦¬ ì¤‘...\")\n",
    "            os.system(f'fusermount -u {mount_point} 2>/dev/null || true')\n",
    "            shutil.rmtree(mount_point, ignore_errors=True)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Google Drive ë§ˆìš´íŠ¸\n",
    "    drive.mount(mount_point, force_remount=True)\n",
    "    \n",
    "    # ê²½ë¡œ ì„¤ì •\n",
    "    BASE_PATH = '/content/drive/MyDrive/'\n",
    "    MODEL_1E4_PATH = BASE_PATH + 'hyperclova-deobfuscation-lora-1e-4-learning-rate'\n",
    "    MODEL_5E4_PATH = BASE_PATH + 'hyperclova-deobfuscation-lora-5e-4-learning-rate'\n",
    "    TEST_DATA_PATH = BASE_PATH + 'testdata.csv'\n",
    "    \n",
    "    # Google Drive ë£¨íŠ¸ì— ì „ìš© ë¶„ì„ ê²°ê³¼ í´ë” ìƒì„±\n",
    "    analysis_root_dir = os.path.join(BASE_PATH, 'HyperCLOVAX_LearningRate_Analysis_Results')\n",
    "    os.makedirs(analysis_root_dir, exist_ok=True)\n",
    "    print(f\"ë¶„ì„ ê²°ê³¼ ë£¨íŠ¸ í´ë” ìƒì„±: {analysis_root_dir}\")\n",
    "    \n",
    "except ImportError:\n",
    "    # ë¡œì»¬ ì‹¤í–‰ ì‹œ\n",
    "    BASE_PATH = './'\n",
    "    MODEL_1E4_PATH = './hyperclova-deobfuscation-lora-1e-4-learning-rate'\n",
    "    MODEL_5E4_PATH = './hyperclova-deobfuscation-lora-5e-4-learning-rate'\n",
    "    TEST_DATA_PATH = './testdata.csv'\n",
    "    \n",
    "    # ë¡œì»¬ìš© ë¶„ì„ ê²°ê³¼ í´ë”\n",
    "    analysis_root_dir = './HyperCLOVAX_LearningRate_Analysis_Results'\n",
    "    os.makedirs(analysis_root_dir, exist_ok=True)\n",
    "    print(f\"ë¶„ì„ ê²°ê³¼ ë£¨íŠ¸ í´ë” ìƒì„±: {analysis_root_dir}\")\n",
    "\n",
    "# ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„± (ë¶„ì„ ê²°ê³¼ í´ë” ë‚´ì—)\n",
    "image_save_dir = os.path.join(analysis_root_dir, 'visualization_images')\n",
    "os.makedirs(image_save_dir, exist_ok=True)\n",
    "print(f\"ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±: {image_save_dir}\")\n",
    "\n",
    "print(f\"\\nê²½ë¡œ ì„¤ì • ì™„ë£Œ:\")\n",
    "print(f\"1e-4 ëª¨ë¸ ê²½ë¡œ: {MODEL_1E4_PATH}\")\n",
    "print(f\"5e-4 ëª¨ë¸ ê²½ë¡œ: {MODEL_5E4_PATH}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ: {TEST_DATA_PATH}\")\n",
    "print(f\"ë¶„ì„ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {analysis_root_dir}\")\n",
    "print(f\"ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ: {image_save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe95a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {len(test_df)} ìƒ˜í”Œ\")\n",
    "print(f\"ì»¬ëŸ¼ ëª©ë¡: {test_df.columns.tolist()}\")\n",
    "print(\"\\nì²« 5ê°œ ìƒ˜í”Œ:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# ë°ì´í„° í†µê³„\n",
    "print(\"\\në°ì´í„° í†µê³„:\")\n",
    "print(f\"- ì´ ìƒ˜í”Œ ìˆ˜: {len(test_df)}\")\n",
    "print(f\"- ì›ë³¸ í…ìŠ¤íŠ¸ í‰ê·  ê¸¸ì´: {test_df['original'].str.len().mean():.1f}\")\n",
    "print(f\"- ë‚œë…í™” í…ìŠ¤íŠ¸ í‰ê·  ê¸¸ì´: {test_df['obfuscated'].str.len().mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c660f8",
   "metadata": {},
   "source": [
    "## 3. ëª¨ë¸ ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e59ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë² ì´ìŠ¤ ëª¨ë¸ ì´ë¦„ ì„¤ì •\n",
    "BASE_MODEL_NAME = \"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B\"\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "print(\"í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_1E4_PATH)\n",
    "print(f\"í† í¬ë‚˜ì´ì € ì–´íœ˜ í¬ê¸°: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83913712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, model_name):\n",
    "    \"\"\"ë¡œë¼ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤\"\"\"\n",
    "    print(f\"\\n{model_name} ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "    \n",
    "    # ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL_NAME,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # LoRA ì–´ëŒ‘í„° ì ìš©\n",
    "    model = PeftModel.from_pretrained(base_model, model_path)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"{model_name} ëª¨ë¸ ë¡œë”© ì™„ë£Œ\")\n",
    "    return model\n",
    "\n",
    "def load_base_model():\n",
    "    \"\"\"ì›ë³¸ ë² ì´ìŠ¤ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤\"\"\"\n",
    "    print(\"\\nì›ë³¸ ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "    \n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL_NAME,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    base_model = base_model.to(device)\n",
    "    \n",
    "    print(\"ì›ë³¸ ëª¨ë¸ ë¡œë”© ì™„ë£Œ\")\n",
    "    return base_model\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "base_model = load_base_model()\n",
    "model_1e4 = load_model(MODEL_1E4_PATH, \"1e-4 Learning Rate ëª¨ë¸\")\n",
    "model_5e4 = load_model(MODEL_5E4_PATH, \"5e-4 Learning Rate ëª¨ë¸\")\n",
    "\n",
    "print(\"ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212eb373",
   "metadata": {},
   "source": [
    "## 4. ì¶”ë¡  í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_deobfuscated_text(model, obfuscated_text, max_length=256):\n",
    "    \"\"\"ë‚œë…í™”ëœ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ì›ë³¸ í…ìŠ¤íŠ¸ ìƒì„±\"\"\"\n",
    "    prompt = f\"\"\"### ì§€ì‹œì‚¬í•­:\n",
    "ë‹¤ìŒ ë‚œë…í™”ëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì›ë˜ í…ìŠ¤íŠ¸ë¡œ ë³µì›í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë‚œë…í™”ëœ í…ìŠ¤íŠ¸: {obfuscated_text}\n",
    "\n",
    "### ì‘ë‹µ:\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_length,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # ì‘ë‹µ ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "    if \"### ì‘ë‹µ:\" in response:\n",
    "        response = response.split(\"### ì‘ë‹µ:\")[1].strip()\n",
    "        # ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°\n",
    "        if \"<|endoftext|>\" in response:\n",
    "            response = response.split(\"<|endoftext|>\")[0].strip()\n",
    "    \n",
    "    return response, inference_time\n",
    "\n",
    "print(\"ì¶”ë¡  í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eaac22",
   "metadata": {},
   "source": [
    "## 5. ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ë©”íŠ¸ë¦­ ë¡œë“œ\n",
    "bleu = load(\"bleu\")\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "def calculate_character_accuracy(pred, ref):\n",
    "    \"\"\"ë¬¸ì ë‹¨ìœ„ ì •í™•ë„ ê³„ì‚°\"\"\"\n",
    "    if len(ref) == 0:\n",
    "        return 1.0 if len(pred) == 0 else 0.0\n",
    "    \n",
    "    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë¬¸ì ìˆ˜ ê³„ì‚°\n",
    "    matches = sum(1 for i, char in enumerate(pred) if i < len(ref) and char == ref[i])\n",
    "    return matches / len(ref)\n",
    "\n",
    "def calculate_exact_match(pred, ref):\n",
    "    \"\"\"ì™„ì „ ì¼ì¹˜ ì—¬ë¶€\"\"\"\n",
    "    return 1.0 if pred.strip() == ref.strip() else 0.0\n",
    "\n",
    "def calculate_metrics(predictions, references):\n",
    "    \"\"\"ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚°\"\"\"\n",
    "    # BLEU ê³„ì‚°\n",
    "    try:\n",
    "        bleu_score = bleu.compute(predictions=predictions, references=[[ref] for ref in references])['bleu']\n",
    "    except:\n",
    "        bleu_score = 0.0\n",
    "    \n",
    "    # ROUGE ê³„ì‚°\n",
    "    try:\n",
    "        rouge_scores = rouge.compute(predictions=predictions, references=references)\n",
    "    except:\n",
    "        rouge_scores = {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
    "    \n",
    "    # ë¬¸ì ì •í™•ë„ ê³„ì‚°\n",
    "    char_accuracies = [calculate_character_accuracy(pred, ref) for pred, ref in zip(predictions, references)]\n",
    "    avg_char_accuracy = np.mean(char_accuracies)\n",
    "    \n",
    "    # ì™„ì „ ì¼ì¹˜ìœ¨ ê³„ì‚°\n",
    "    exact_matches = [calculate_exact_match(pred, ref) for pred, ref in zip(predictions, references)]\n",
    "    exact_match_rate = np.mean(exact_matches)\n",
    "    \n",
    "    return {\n",
    "        'bleu': bleu_score,\n",
    "        'rouge1': rouge_scores['rouge1'],\n",
    "        'rouge2': rouge_scores['rouge2'],\n",
    "        'rougeL': rouge_scores['rougeL'],\n",
    "        'char_accuracy': avg_char_accuracy,\n",
    "        'exact_match': exact_match_rate,\n",
    "        'char_accuracies': char_accuracies,\n",
    "        'exact_matches': exact_matches\n",
    "    }\n",
    "\n",
    "print(\"í‰ê°€ ë©”íŠ¸ë¦­ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e3322",
   "metadata": {},
   "source": [
    "## 6. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, test_df, sample_size=None):\n",
    "    \"\"\"ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\"\"\"\n",
    "    if sample_size:\n",
    "        test_data = test_df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        test_data = test_df.copy()\n",
    "    \n",
    "    print(f\"\\n{model_name} í‰ê°€ ì‹œì‘ ({len(test_data)}ê°œ ìƒ˜í”Œ)\")\n",
    "    \n",
    "    predictions = []\n",
    "    inference_times = []\n",
    "    \n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data), desc=f\"{model_name} í‰ê°€\"):\n",
    "        obfuscated = row['obfuscated']\n",
    "        pred, inf_time = generate_deobfuscated_text(model, obfuscated)\n",
    "        predictions.append(pred)\n",
    "        inference_times.append(inf_time)\n",
    "    \n",
    "    # ì°¸ì¡° í…ìŠ¤íŠ¸\n",
    "    references = test_data['original'].tolist()\n",
    "    \n",
    "    # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    metrics = calculate_metrics(predictions, references)\n",
    "    \n",
    "    # ì¶”ë¡  ì‹œê°„ í†µê³„\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    total_inference_time = np.sum(inference_times)\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'predictions': predictions,\n",
    "        'references': references,\n",
    "        'inference_times': inference_times,\n",
    "        'avg_inference_time': avg_inference_time,\n",
    "        'total_inference_time': total_inference_time,\n",
    "        'test_data': test_data,\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name} í‰ê°€ ì™„ë£Œ\")\n",
    "    print(f\"í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_inference_time:.3f}ì´ˆ\")\n",
    "    print(f\"ì´ ì¶”ë¡  ì‹œê°„: {total_inference_time:.1f}ì´ˆ\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰ (ì „ì²´ ë°ì´í„°ì…‹ ë˜ëŠ” ìƒ˜í”Œ)\n",
    "SAMPLE_SIZE = 200  # ì „ì²´ í‰ê°€ë¥¼ ì›í•˜ë©´ Noneìœ¼ë¡œ ì„¤ì •\n",
    "\n",
    "print(\"ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "results_base = evaluate_model(base_model, \"ì›ë³¸ ëª¨ë¸\", test_df, SAMPLE_SIZE)\n",
    "results_1e4 = evaluate_model(model_1e4, \"1e-4 Learning Rate ëª¨ë¸\", test_df, SAMPLE_SIZE)\n",
    "results_5e4 = evaluate_model(model_5e4, \"5e-4 Learning Rate ëª¨ë¸\", test_df, SAMPLE_SIZE)\n",
    "\n",
    "print(\"\\nëª¨ë“  ëª¨ë¸ í‰ê°€ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18542a41",
   "metadata": {},
   "source": [
    "## 7. ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ ë¹„êµ í‘œ ìƒì„±\n",
    "comparison_df = pd.DataFrame({\n",
    "    'ë©”íŠ¸ë¦­': ['BLEU ì ìˆ˜', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L',\n",
    "               'ë¬¸ì ì •í™•ë„', 'ì •í™• ì¼ì¹˜ìœ¨', 'í‰ê·  ì¶”ë¡  ì‹œê°„(ì´ˆ)'],\n",
    "    'ì›ë³¸ ëª¨ë¸': [\n",
    "        f\"{results_base['bleu']:.4f}\",\n",
    "        f\"{results_base['rouge1']:.4f}\",\n",
    "        f\"{results_base['rouge2']:.4f}\",\n",
    "        f\"{results_base['rougeL']:.4f}\",\n",
    "        f\"{results_base['char_accuracy']:.4f}\",\n",
    "        f\"{results_base['exact_match']:.4f}\",\n",
    "        f\"{results_base['avg_inference_time']:.3f}\"\n",
    "    ],\n",
    "    '1e-4 Learning Rate ëª¨ë¸': [\n",
    "        f\"{results_1e4['bleu']:.4f}\",\n",
    "        f\"{results_1e4['rouge1']:.4f}\",\n",
    "        f\"{results_1e4['rouge2']:.4f}\",\n",
    "        f\"{results_1e4['rougeL']:.4f}\",\n",
    "        f\"{results_1e4['char_accuracy']:.4f}\",\n",
    "        f\"{results_1e4['exact_match']:.4f}\",\n",
    "        f\"{results_1e4['avg_inference_time']:.3f}\"\n",
    "    ],\n",
    "    '5e-4 Learning Rate ëª¨ë¸': [\n",
    "        f\"{results_5e4['bleu']:.4f}\",\n",
    "        f\"{results_5e4['rouge1']:.4f}\",\n",
    "        f\"{results_5e4['rouge2']:.4f}\",\n",
    "        f\"{results_5e4['rougeL']:.4f}\",\n",
    "        f\"{results_5e4['char_accuracy']:.4f}\",\n",
    "        f\"{results_5e4['exact_match']:.4f}\",\n",
    "        f\"{results_5e4['avg_inference_time']:.3f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=== ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ===\\n(ì›ë³¸ vs 1e-4 vs 5e-4 Learning Rate)\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ ë¯¸ì„¸ì¡°ì • ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ë¥  ê³„ì‚°\n",
    "print(\"\\n=== ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ ë¯¸ì„¸ì¡°ì • ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ìœ¨ ===\")\n",
    "metrics_to_compare = ['bleu', 'rouge1', 'rouge2', 'rougeL', 'char_accuracy', 'exact_match']\n",
    "print(f\"{'Metric':<15} {'1e-4 vs ì›ë³¸':<20} {'5e-4 vs ì›ë³¸':<20}\")\n",
    "print(\"-\" * 60)\n",
    "for metric in metrics_to_compare:\n",
    "    improvement_1e4 = ((results_1e4[metric] - results_base[metric]) / results_base[metric]) * 100 if results_base[metric] > 0 else 0\n",
    "    improvement_5e4 = ((results_5e4[metric] - results_base[metric]) / results_base[metric]) * 100 if results_base[metric] > 0 else 0\n",
    "    print(f\"{metric.upper():<15} {improvement_1e4:+7.2f}%          {improvement_5e4:+7.2f}%\")\n",
    "\n",
    "# 1e-4 vs 5e-4 ëª¨ë¸ ë¹„êµ\n",
    "print(\"\\n=== 5e-4 ëª¨ë¸ vs 1e-4 ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ìœ¨ ===\")\n",
    "for metric in metrics_to_compare:\n",
    "    improvement = ((results_5e4[metric] - results_1e4[metric]) / results_1e4[metric]) * 100 if results_1e4[metric] > 0 else 0\n",
    "    print(f\"{metric.upper()}: {improvement:+.2f}%\")\n",
    "\n",
    "# ì¶”ë¡  ì‹œê°„ ë¹„ìœ¨ ë¹„êµ\n",
    "time_ratio_base_1e4 = results_1e4['avg_inference_time'] / results_base['avg_inference_time']\n",
    "time_ratio_base_5e4 = results_5e4['avg_inference_time'] / results_base['avg_inference_time']\n",
    "time_ratio_1e4_5e4 = results_5e4['avg_inference_time'] / results_1e4['avg_inference_time']\n",
    "\n",
    "print(f\"\\n=== ì¶”ë¡  ì‹œê°„ ë¹„ìœ¨ ë¹„êµ ===\")\n",
    "print(f\"ì¶”ë¡  ì‹œê°„ ë¹„ìœ¨ (1e-4/ì›ë³¸): {time_ratio_base_1e4:.2f}x\")\n",
    "print(f\"ì¶”ë¡  ì‹œê°„ ë¹„ìœ¨ (5e-4/ì›ë³¸): {time_ratio_base_5e4:.2f}x\")\n",
    "print(f\"ì¶”ë¡  ì‹œê°„ ë¹„ìœ¨ (5e-4/1e-4): {time_ratio_1e4_5e4:.2f}x\")\n",
    "\n",
    "# ì „ë°˜ì ì¸ ì„±ëŠ¥ ìš”ì•½\n",
    "best_finetuned_accuracy = max(results_1e4['char_accuracy'], results_5e4['char_accuracy'])\n",
    "best_model_name = \"1e-4 Learning Rate\" if results_1e4['char_accuracy'] > results_5e4['char_accuracy'] else \"5e-4 Learning Rate\"\n",
    "accuracy_improvement = ((best_finetuned_accuracy - results_base['char_accuracy']) / results_base['char_accuracy'] * 100)\n",
    "\n",
    "print(f\"\\n=== ì „ë°˜ì  ì„±ëŠ¥ ìš”ì•½ ===\")\n",
    "print(f\"ê°€ì¥ ìš°ìˆ˜í•œ ëª¨ë¸: {best_model_name} ëª¨ë¸\")\n",
    "print(f\"ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ ìµœëŒ€ ì„±ëŠ¥ í–¥ìƒ: {accuracy_improvement:.2f}%\")\n",
    "print(f\"ë¯¸ì„¸ì¡°ì • íš¨ê³¼: {'significant' if accuracy_improvement > 10 else 'moderate' if accuracy_improvement > 5 else 'limited'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540b5d9",
   "metadata": {},
   "source": [
    "## 8. ì‹œê°í™” ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Metric Comparison Bar Chart\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Model Performance Comparison Analysis (Base vs Fine-tuned with Different Learning Rates)', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics_data = {\n",
    "    'BLEU': [results_base['bleu'], results_1e4['bleu'], results_5e4['bleu']],\n",
    "    'ROUGE-1': [results_base['rouge1'], results_1e4['rouge1'], results_5e4['rouge1']],\n",
    "    'ROUGE-2': [results_base['rouge2'], results_1e4['rouge2'], results_5e4['rouge2']],\n",
    "    'ROUGE-L': [results_base['rougeL'], results_1e4['rougeL'], results_5e4['rougeL']],\n",
    "    'Character Accuracy': [results_base['char_accuracy'], results_1e4['char_accuracy'], results_5e4['char_accuracy']],\n",
    "    'Exact Match': [results_base['exact_match'], results_1e4['exact_match'], results_5e4['exact_match']]\n",
    "}\n",
    "\n",
    "models = ['Base Model', '1e-4 LR Model', '5e-4 LR Model']\n",
    "colors = ['lightgray', 'skyblue', 'lightcoral']\n",
    "\n",
    "for idx, (metric, values) in enumerate(metrics_data.items()):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    bars = axes[row, col].bar(models, values, color=colors, alpha=0.7, edgecolor='black')\n",
    "    axes[row, col].set_title(f'{metric}', fontweight='bold')\n",
    "    axes[row, col].set_ylabel('Score')\n",
    "    axes[row, col].set_ylim(0, max(values) * 1.1)\n",
    "    axes[row, col].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Display values\n",
    "    for bar, value in zip(bars, values):\n",
    "        axes[row, col].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,\n",
    "                           f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "# ì´ë¯¸ì§€ ì €ì¥\n",
    "img_path = os.path.join(image_save_dir, '01_learning_rate_performance_comparison.png')\n",
    "plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"ì´ë¯¸ì§€ ì €ì¥: {img_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Character Accuracy Distribution Comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# ì›ë³¸ ëª¨ë¸\n",
    "axes[0].hist(results_base['char_accuracies'], bins=20, alpha=0.7, color='lightgray', edgecolor='black')\n",
    "axes[0].set_title('Base Model - Character Accuracy Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Character Accuracy')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(results_base['char_accuracy'], color='red', linestyle='--', \n",
    "                label=f'Mean: {results_base[\"char_accuracy\"]:.3f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# 1e-4 ëª¨ë¸\n",
    "axes[1].hist(results_1e4['char_accuracies'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[1].set_title('1e-4 Learning Rate Model - Character Accuracy Distribution', fontweight='bold')\n",
    "axes[1].set_xlabel('Character Accuracy')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].axvline(results_1e4['char_accuracy'], color='red', linestyle='--', \n",
    "                label=f'Mean: {results_1e4[\"char_accuracy\"]:.3f}')\n",
    "axes[1].legend()\n",
    "\n",
    "# 5e-4 ëª¨ë¸\n",
    "axes[2].hist(results_5e4['char_accuracies'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[2].set_title('5e-4 Learning Rate Model - Character Accuracy Distribution', fontweight='bold')\n",
    "axes[2].set_xlabel('Character Accuracy')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].axvline(results_5e4['char_accuracy'], color='red', linestyle='--',\n",
    "                label=f'Mean: {results_5e4[\"char_accuracy\"]:.3f}')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# ì´ë¯¸ì§€ ì €ì¥\n",
    "img_path = os.path.join(image_save_dir, '02_character_accuracy_distribution.png')\n",
    "plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"ì´ë¯¸ì§€ ì €ì¥: {img_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388bdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Inference Time Comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Inference time distribution\n",
    "inference_data = [results_base['inference_times'], results_1e4['inference_times'], results_5e4['inference_times']]\n",
    "labels = ['Base Model', '1e-4 LR Model', '5e-4 LR Model']\n",
    "\n",
    "axes[0].boxplot(inference_data, labels=labels, patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                medianprops=dict(color='red', linewidth=2))\n",
    "axes[0].set_title('Inference Time Distribution Comparison', fontweight='bold')\n",
    "axes[0].set_ylabel('Inference Time (seconds)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Average inference time bar chart\n",
    "avg_times = [results_base['avg_inference_time'], results_1e4['avg_inference_time'], results_5e4['avg_inference_time']]\n",
    "colors = ['lightgray', 'skyblue', 'lightcoral']\n",
    "bars = axes[1].bar(labels, avg_times, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Average Inference Time Comparison', fontweight='bold')\n",
    "axes[1].set_ylabel('Average Inference Time (seconds)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "for bar, time_val in zip(bars, avg_times):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(avg_times)*0.01,\n",
    "                f'{time_val:.3f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "# ì´ë¯¸ì§€ ì €ì¥\n",
    "img_path = os.path.join(image_save_dir, '03_inference_time_comparison.png')\n",
    "plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"ì´ë¯¸ì§€ ì €ì¥: {img_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c6546",
   "metadata": {},
   "source": [
    "## 9. ì§ˆì  ë¶„ì„ - ì˜ˆì‹œ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1944f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°€ì¥ ì„±ëŠ¥ ì°¨ì´ê°€ í° ìƒ˜í”Œë“¤ ì°¾ê¸°\n",
    "def find_performance_difference_samples(results_base, results_1e4, results_5e4, n_samples=5):\n",
    "    \"\"\"ì„¸ ëª¨ë¸ ê°„ ì„±ëŠ¥ ì°¨ì´ê°€ í° ìƒ˜í”Œë“¤ ì°¾ê¸°\"\"\"\n",
    "    char_acc_base = np.array(results_base['char_accuracies'])\n",
    "    char_acc_1e4 = np.array(results_1e4['char_accuracies'])\n",
    "    char_acc_5e4 = np.array(results_5e4['char_accuracies'])\n",
    "    \n",
    "    # ë¯¸ì„¸ì¡°ì • íš¨ê³¼ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸ vs ì›ë³¸)\n",
    "    max_finetuned = np.maximum(char_acc_1e4, char_acc_5e4)\n",
    "    finetuning_improvement = max_finetuned - char_acc_base\n",
    "    \n",
    "    # 5e-4 vs 1e-4 ë¹„êµ\n",
    "    diff_5e4_1e4 = char_acc_5e4 - char_acc_1e4\n",
    "    \n",
    "    # ê°€ì¥ ë¯¸ì„¸ì¡°ì • íš¨ê³¼ê°€ í° ì¸ë±ìŠ¤ë“¤\n",
    "    best_finetuning_idx = np.argsort(finetuning_improvement)[-n_samples:][::-1]\n",
    "    worst_finetuning_idx = np.argsort(finetuning_improvement)[:n_samples]\n",
    "    \n",
    "    # 5e-4ê°€ 1e-4ë³´ë‹¤ í›¨ì”¬ ì¢‹ì€/ë‚˜ìœ ê²½ìš°\n",
    "    best_5e4_vs_1e4_idx = np.argsort(diff_5e4_1e4)[-n_samples:][::-1]\n",
    "    worst_5e4_vs_1e4_idx = np.argsort(diff_5e4_1e4)[:n_samples]\n",
    "    \n",
    "    return best_finetuning_idx, worst_finetuning_idx, best_5e4_vs_1e4_idx, worst_5e4_vs_1e4_idx\n",
    "\n",
    "best_ft_idx, worst_ft_idx, best_5e4_idx, worst_5e4_idx = find_performance_difference_samples(results_base, results_1e4, results_5e4)\n",
    "\n",
    "print(\"=== ë¯¸ì„¸ì¡°ì •ì´ ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ ê°€ì¥ íš¨ê³¼ì ì´ì—ˆë˜ ì˜ˆì‹œ ===\")\n",
    "for i, idx in enumerate(best_ft_idx):\n",
    "    print(f\"\\n[ì˜ˆì‹œ {i+1}]\")\n",
    "    print(f\"ë‚œë…í™” í…ìŠ¤íŠ¸: {results_base['test_data'].iloc[idx]['obfuscated']}\")\n",
    "    print(f\"ì •ë‹µ í…ìŠ¤íŠ¸: {results_base['references'][idx]}\")\n",
    "    print(f\"ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡: {results_base['predictions'][idx]}\")\n",
    "    print(f\"1e-4 ëª¨ë¸ ì˜ˆì¸¡: {results_1e4['predictions'][idx]}\")\n",
    "    print(f\"5e-4 ëª¨ë¸ ì˜ˆì¸¡: {results_5e4['predictions'][idx]}\")\n",
    "    print(f\"ë¬¸ì ì •í™•ë„ - ì›ë³¸: {results_base['char_accuracies'][idx]:.3f}, 1e-4: {results_1e4['char_accuracies'][idx]:.3f}, 5e-4: {results_5e4['char_accuracies'][idx]:.3f}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "print(\"\\n=== 5e-4 ëª¨ë¸ì´ 1e-4 ëª¨ë¸ ëŒ€ë¹„ í¬ê²Œ ìš°ìˆ˜í–ˆë˜ ì˜ˆì‹œ ===\")\n",
    "for i, idx in enumerate(best_5e4_idx):\n",
    "    print(f\"\\n[ì˜ˆì‹œ {i+1}]\")\n",
    "    print(f\"ë‚œë…í™” í…ìŠ¤íŠ¸: {results_1e4['test_data'].iloc[idx]['obfuscated']}\")\n",
    "    print(f\"ì •ë‹µ í…ìŠ¤íŠ¸: {results_1e4['references'][idx]}\")\n",
    "    print(f\"1e-4 ëª¨ë¸ ì˜ˆì¸¡: {results_1e4['predictions'][idx]}\")\n",
    "    print(f\"5e-4 ëª¨ë¸ ì˜ˆì¸¡: {results_5e4['predictions'][idx]}\")\n",
    "    print(f\"ë¬¸ì ì •í™•ë„ - 1e-4: {results_1e4['char_accuracies'][idx]:.3f}, 5e-4: {results_5e4['char_accuracies'][idx]:.3f}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "print(\"\\n=== ë¯¸ì„¸ì¡°ì • íš¨ê³¼ê°€ ì œí•œì ì´ì—ˆë˜ ì˜ˆì‹œ ===\")\n",
    "for i, idx in enumerate(worst_ft_idx):\n",
    "    print(f\"\\n[ì˜ˆì‹œ {i+1}]\")\n",
    "    print(f\"ë‚œë…í™” í…ìŠ¤íŠ¸: {results_base['test_data'].iloc[idx]['obfuscated']}\")\n",
    "    print(f\"ì •ë‹µ í…ìŠ¤íŠ¸: {results_base['references'][idx]}\")\n",
    "    print(f\"ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡: {results_base['predictions'][idx]}\")\n",
    "    print(f\"1e-4 ëª¨ë¸ ì˜ˆì¸¡: {results_1e4['predictions'][idx]}\")\n",
    "    print(f\"5e-4 ëª¨ë¸ ì˜ˆì¸¡: {results_5e4['predictions'][idx]}\")\n",
    "    print(f\"ë¬¸ì ì •í™•ë„ - ì›ë³¸: {results_base['char_accuracies'][idx]:.3f}, 1e-4: {results_1e4['char_accuracies'][idx]:.3f}, 5e-4: {results_5e4['char_accuracies'][idx]:.3f}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "# ì „ë°˜ì ì¸ ì„±ëŠ¥ ë¹„êµ í†µê³„\n",
    "print(\"\\n=== ì „ë°˜ì ì¸ ì„±ëŠ¥ ë¹„êµ í†µê³„ ===\")\n",
    "char_acc_base = np.array(results_base['char_accuracies'])\n",
    "char_acc_1e4 = np.array(results_1e4['char_accuracies'])\n",
    "char_acc_5e4 = np.array(results_5e4['char_accuracies'])\n",
    "\n",
    "# ì›ë³¸ ëŒ€ë¹„ ë¯¸ì„¸ì¡°ì • ëª¨ë¸ ì„±ëŠ¥\n",
    "better_1e4_vs_base = np.sum(char_acc_1e4 > char_acc_base)\n",
    "better_5e4_vs_base = np.sum(char_acc_5e4 > char_acc_base)\n",
    "\n",
    "# 1e-4 vs 5e-4 ë¹„êµ\n",
    "better_5e4_vs_1e4 = np.sum(char_acc_5e4 > char_acc_1e4)\n",
    "better_1e4_vs_5e4 = np.sum(char_acc_1e4 > char_acc_5e4)\n",
    "tie_1e4_5e4 = np.sum(char_acc_1e4 == char_acc_5e4)\n",
    "\n",
    "print(f\"1e-4 ëª¨ë¸ > ì›ë³¸ ëª¨ë¸: {better_1e4_vs_base}ê°œ ({better_1e4_vs_base/len(char_acc_base)*100:.1f}%)\")\n",
    "print(f\"5e-4 ëª¨ë¸ > ì›ë³¸ ëª¨ë¸: {better_5e4_vs_base}ê°œ ({better_5e4_vs_base/len(char_acc_base)*100:.1f}%)\")\n",
    "print(f\"5e-4 ëª¨ë¸ > 1e-4 ëª¨ë¸: {better_5e4_vs_1e4}ê°œ ({better_5e4_vs_1e4/len(char_acc_1e4)*100:.1f}%)\")\n",
    "print(f\"1e-4 ëª¨ë¸ > 5e-4 ëª¨ë¸: {better_1e4_vs_5e4}ê°œ ({better_1e4_vs_5e4/len(char_acc_1e4)*100:.1f}%)\")\n",
    "print(f\"ë™ì : {tie_1e4_5e4}ê°œ ({tie_1e4_5e4/len(char_acc_1e4)*100:.1f}%)\")\n",
    "\n",
    "avg_improvement_1e4 = np.mean(char_acc_1e4 - char_acc_base)\n",
    "avg_improvement_5e4 = np.mean(char_acc_5e4 - char_acc_base)\n",
    "print(f\"\\n1e-4 ëª¨ë¸ì˜ ì›ë³¸ ëŒ€ë¹„ í‰ê·  ì„±ëŠ¥ ê°œì„ : {avg_improvement_1e4:.4f} ({avg_improvement_1e4*100:.2f}%p)\")\n",
    "print(f\"5e-4 ëª¨ë¸ì˜ ì›ë³¸ ëŒ€ë¹„ í‰ê·  ì„±ëŠ¥ ê°œì„ : {avg_improvement_5e4:.4f} ({avg_improvement_5e4*100:.2f}%p)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91017b0",
   "metadata": {},
   "source": [
    "## 10. ìƒì„¸ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ ê¸¸ì´ë³„ ì„±ëŠ¥ ë¶„ì„\n",
    "def analyze_by_text_length(results, model_name):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ê¸¸ì´ë³„ ì„±ëŠ¥ ë¶„ì„\"\"\"\n",
    "    test_data = results['test_data']\n",
    "    char_accuracies = results['char_accuracies']\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°\n",
    "    text_lengths = test_data['original'].str.len()\n",
    "    \n",
    "    # ê¸¸ì´ êµ¬ê°„ë³„ë¡œ ë¶„ë¥˜\n",
    "    length_bins = [0, 20, 50, 100, 200, float('inf')]\n",
    "    length_labels = ['â‰¤20 chars', '21-50 chars', '51-100 chars', '101-200 chars', '200+ chars']\n",
    "    \n",
    "    length_categories = pd.cut(text_lengths, bins=length_bins, labels=length_labels, right=False)\n",
    "    \n",
    "    # êµ¬ê°„ë³„ í‰ê·  ì„±ëŠ¥\n",
    "    performance_by_length = []\n",
    "    for category in length_labels:\n",
    "        mask = length_categories == category\n",
    "        if mask.sum() > 0:\n",
    "            avg_acc = np.mean(np.array(char_accuracies)[mask])\n",
    "            count = mask.sum()\n",
    "            performance_by_length.append({\n",
    "                'length_category': category,\n",
    "                'avg_char_accuracy': avg_acc,\n",
    "                'count': count\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(performance_by_length)\n",
    "\n",
    "# ì„¸ ëª¨ë¸ì˜ ê¸¸ì´ë³„ ì„±ëŠ¥ ë¶„ì„\n",
    "length_analysis_base = analyze_by_text_length(results_base, \"ì›ë³¸ ëª¨ë¸\")\n",
    "length_analysis_1e4 = analyze_by_text_length(results_1e4, \"1e-4 ëª¨ë¸\")\n",
    "length_analysis_5e4 = analyze_by_text_length(results_5e4, \"5e-4 ëª¨ë¸\")\n",
    "\n",
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(length_analysis_base))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, length_analysis_base['avg_char_accuracy'], width, \n",
    "               label='Base Model', color='lightgray', alpha=0.7)\n",
    "bars2 = ax.bar(x, length_analysis_1e4['avg_char_accuracy'], width,\n",
    "               label='1e-4 LR Model', color='skyblue', alpha=0.7)\n",
    "bars3 = ax.bar(x + width, length_analysis_5e4['avg_char_accuracy'], width,\n",
    "               label='5e-4 LR Model', color='lightcoral', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Text Length Category')\n",
    "ax.set_ylabel('Average Character Accuracy')\n",
    "ax.set_title('Model Performance Comparison by Text Length (Base vs Fine-tuned with Different LR)', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(length_analysis_base['length_category'], rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "# Display values\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "# ì´ë¯¸ì§€ ì €ì¥\n",
    "img_path = os.path.join(image_save_dir, '04_performance_by_text_length.png')\n",
    "plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"ì´ë¯¸ì§€ ì €ì¥: {img_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"=== í…ìŠ¤íŠ¸ ê¸¸ì´ë³„ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ===\")\n",
    "combined_length_analysis = pd.merge(\n",
    "    pd.merge(length_analysis_base, length_analysis_1e4, on='length_category', suffixes=('_base', '_1e4')),\n",
    "    length_analysis_5e4, on='length_category'\n",
    ")\n",
    "combined_length_analysis.columns = ['length_category', 'avg_char_accuracy_base', 'count_base', \n",
    "                                   'avg_char_accuracy_1e4', 'count_1e4', 'avg_char_accuracy_5e4', 'count_5e4']\n",
    "print(combined_length_analysis[['length_category', 'avg_char_accuracy_base', 'avg_char_accuracy_1e4', 'avg_char_accuracy_5e4']])\n",
    "\n",
    "# ê¸¸ì´ë³„ ë¯¸ì„¸ì¡°ì • íš¨ê³¼ ë¶„ì„\n",
    "print(\"\\n=== ê¸¸ì´ë³„ ë¯¸ì„¸ì¡°ì • íš¨ê³¼ ===\")\n",
    "for _, row in combined_length_analysis.iterrows():\n",
    "    category = row['length_category']\n",
    "    base_acc = row['avg_char_accuracy_base']\n",
    "    acc_1e4 = row['avg_char_accuracy_1e4']\n",
    "    acc_5e4 = row['avg_char_accuracy_5e4']\n",
    "    \n",
    "    improvement_1e4 = ((acc_1e4 - base_acc) / base_acc * 100) if base_acc > 0 else 0\n",
    "    improvement_5e4 = ((acc_5e4 - base_acc) / base_acc * 100) if base_acc > 0 else 0\n",
    "    \n",
    "    print(f\"{category}: 1e-4 ê°œì„  {improvement_1e4:+.1f}%, 5e-4 ê°œì„  {improvement_5e4:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì™„ì „ ì¼ì¹˜ ë° ë¶€ë¶„ ì¼ì¹˜ ë¶„ì„\n",
    "def analyze_match_types(results, model_name):\n",
    "    \"\"\"ì™„ì „ ì¼ì¹˜ ë° ë¶€ë¶„ ì¼ì¹˜ ë¶„ì„\"\"\"\n",
    "    predictions = results['predictions']\n",
    "    references = results['references']\n",
    "    \n",
    "    perfect_matches = 0\n",
    "    high_accuracy = 0  # 90% ì´ìƒ\n",
    "    medium_accuracy = 0  # 70-90%\n",
    "    low_accuracy = 0  # 70% ë¯¸ë§Œ\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        char_acc = calculate_character_accuracy(pred, ref)\n",
    "        \n",
    "        if pred.strip() == ref.strip():\n",
    "            perfect_matches += 1\n",
    "        elif char_acc >= 0.9:\n",
    "            high_accuracy += 1\n",
    "        elif char_acc >= 0.7:\n",
    "            medium_accuracy += 1\n",
    "        else:\n",
    "            low_accuracy += 1\n",
    "    \n",
    "    total = len(predictions)\n",
    "    \n",
    "    return {\n",
    "        'perfect_match': perfect_matches,\n",
    "        'high_accuracy': high_accuracy,\n",
    "        'medium_accuracy': medium_accuracy,\n",
    "        'low_accuracy': low_accuracy,\n",
    "        'perfect_match_rate': perfect_matches / total,\n",
    "        'high_accuracy_rate': high_accuracy / total,\n",
    "        'medium_accuracy_rate': medium_accuracy / total,\n",
    "        'low_accuracy_rate': low_accuracy / total\n",
    "    }\n",
    "\n",
    "match_analysis_base = analyze_match_types(results_base, \"ì›ë³¸ ëª¨ë¸\")\n",
    "match_analysis_1e4 = analyze_match_types(results_1e4, \"1e-4 ëª¨ë¸\")\n",
    "match_analysis_5e4 = analyze_match_types(results_5e4, \"5e-4 ëª¨ë¸\")\n",
    "\n",
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "categories = ['Perfect Match', 'High Accuracy\\n(90%+)', 'Medium Accuracy\\n(70-90%)', 'Low Accuracy\\n(<70%)']\n",
    "values_base = [match_analysis_base['perfect_match_rate'], \n",
    "               match_analysis_base['high_accuracy_rate'],\n",
    "               match_analysis_base['medium_accuracy_rate'], \n",
    "               match_analysis_base['low_accuracy_rate']]\n",
    "values_1e4 = [match_analysis_1e4['perfect_match_rate'], \n",
    "              match_analysis_1e4['high_accuracy_rate'],\n",
    "              match_analysis_1e4['medium_accuracy_rate'], \n",
    "              match_analysis_1e4['low_accuracy_rate']]\n",
    "values_5e4 = [match_analysis_5e4['perfect_match_rate'], \n",
    "              match_analysis_5e4['high_accuracy_rate'],\n",
    "              match_analysis_5e4['medium_accuracy_rate'], \n",
    "              match_analysis_5e4['low_accuracy_rate']]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, values_base, width, label='Base Model', color='lightgray', alpha=0.7)\n",
    "bars2 = ax.bar(x, values_1e4, width, label='1e-4 LR Model', color='skyblue', alpha=0.7)\n",
    "bars3 = ax.bar(x + width, values_5e4, width, label='5e-4 LR Model', color='lightcoral', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Accuracy Category')\n",
    "ax.set_ylabel('Proportion')\n",
    "ax.set_title('Sample Distribution by Accuracy Category (Base vs Fine-tuned with Different LR)', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "# Display values\n",
    "for bars, values in zip([bars1, bars2, bars3], [values_base, values_1e4, values_5e4]):\n",
    "    for bar, value in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                f'{value:.1%}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "# ì´ë¯¸ì§€ ì €ì¥\n",
    "img_path = os.path.join(image_save_dir, '05_accuracy_category_distribution.png')\n",
    "plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"ì´ë¯¸ì§€ ì €ì¥: {img_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"=== ì •í™•ë„ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ ê²°ê³¼ ===\")\n",
    "print(f\"{'Category':<20} {'Base Model':<15} {'1e-4 LR Model':<15} {'5e-4 LR Model':<15}\")\n",
    "print(\"-\" * 70)\n",
    "for i, category in enumerate(categories):\n",
    "    print(f\"{category:<20} {values_base[i]:<15.1%} {values_1e4[i]:<15.1%} {values_5e4[i]:<15.1%}\")\n",
    "\n",
    "print(\"\\n=== ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ ê°œì„ ìœ¨ ===\")\n",
    "print(f\"{'Category':<20} {'1e-4 Improvement':<20} {'5e-4 Improvement':<20}\")\n",
    "print(\"-\" * 65)\n",
    "for i, category in enumerate(categories):\n",
    "    improvement_1e4 = ((values_1e4[i] - values_base[i]) / values_base[i] * 100) if values_base[i] > 0 else float('inf') if values_1e4[i] > 0 else 0\n",
    "    improvement_5e4 = ((values_5e4[i] - values_base[i]) / values_base[i] * 100) if values_base[i] > 0 else float('inf') if values_5e4[i] > 0 else 0\n",
    "    \n",
    "    if improvement_1e4 == float('inf'):\n",
    "        imp_1e4_str = \"N/A (0â†’+)\"\n",
    "    else:\n",
    "        imp_1e4_str = f\"{improvement_1e4:+.1f}%\"\n",
    "        \n",
    "    if improvement_5e4 == float('inf'):\n",
    "        imp_5e4_str = \"N/A (0â†’+)\"\n",
    "    else:\n",
    "        imp_5e4_str = f\"{improvement_5e4:+.1f}%\"\n",
    "    \n",
    "    print(f\"{category:<20} {imp_1e4_str:<20} {imp_5e4_str:<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5877e",
   "metadata": {},
   "source": [
    "## 11. ì¢…í•© ê²°ë¡  ë° ì¸ì‚¬ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639dcacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"ğŸ” HyperCLOVAX Learning Rate ë¹„êµ ë¶„ì„ - ì¢…í•© ê²°ë¡  (ì›ë³¸ vs 1e-4 vs 5e-4)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(f\"\"\"\n",
    "ğŸ“Š **ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (ì›ë³¸ vs Learning Rate ë¯¸ì„¸ì¡°ì •)**\n",
    "\n",
    "ğŸ“ˆ **BLEU ì ìˆ˜**\n",
    "- ì›ë³¸: {results_base['bleu']:.4f}\n",
    "- 1e-4: {results_1e4['bleu']:.4f} (ê°œì„ ìœ¨: {((results_1e4['bleu'] - results_base['bleu']) / results_base['bleu'] * 100):+.2f}%)\n",
    "- 5e-4: {results_5e4['bleu']:.4f} (ê°œì„ ìœ¨: {((results_5e4['bleu'] - results_base['bleu']) / results_base['bleu'] * 100):+.2f}%)\n",
    "\n",
    "ğŸ“ˆ **ROUGE-L ì ìˆ˜**\n",
    "- ì›ë³¸: {results_base['rougeL']:.4f}\n",
    "- 1e-4: {results_1e4['rougeL']:.4f} (ê°œì„ ìœ¨: {((results_1e4['rougeL'] - results_base['rougeL']) / results_base['rougeL'] * 100):+.2f}%)\n",
    "- 5e-4: {results_5e4['rougeL']:.4f} (ê°œì„ ìœ¨: {((results_5e4['rougeL'] - results_base['rougeL']) / results_base['rougeL'] * 100):+.2f}%)\n",
    "\n",
    "ğŸ“ˆ **ë¬¸ì ì •í™•ë„**\n",
    "- ì›ë³¸: {results_base['char_accuracy']:.4f}\n",
    "- 1e-4: {results_1e4['char_accuracy']:.4f} (ê°œì„ ìœ¨: {((results_1e4['char_accuracy'] - results_base['char_accuracy']) / results_base['char_accuracy'] * 100):+.2f}%)\n",
    "- 5e-4: {results_5e4['char_accuracy']:.4f} (ê°œì„ ìœ¨: {((results_5e4['char_accuracy'] - results_base['char_accuracy']) / results_base['char_accuracy'] * 100):+.2f}%)\n",
    "\n",
    "ğŸ“ˆ **ì™„ì „ ì¼ì¹˜ìœ¨**\n",
    "- ì›ë³¸: {results_base['exact_match']:.4f}\n",
    "- 1e-4: {results_1e4['exact_match']:.4f} (ê°œì„ ìœ¨: {((results_1e4['exact_match'] - results_base['exact_match']) / results_base['exact_match'] * 100) if results_base['exact_match'] > 0 else float('inf'):+.2f}%)\n",
    "- 5e-4: {results_5e4['exact_match']:.4f} (ê°œì„ ìœ¨: {((results_5e4['exact_match'] - results_base['exact_match']) / results_base['exact_match'] * 100) if results_base['exact_match'] > 0 else float('inf'):+.2f}%)\n",
    "\n",
    "â±ï¸ **íš¨ìœ¨ì„± ë¶„ì„**\n",
    "- ì›ë³¸ ëª¨ë¸ í‰ê·  ì¶”ë¡  ì‹œê°„: {results_base['avg_inference_time']:.3f}ì´ˆ\n",
    "- 1e-4 ëª¨ë¸ í‰ê·  ì¶”ë¡  ì‹œê°„: {results_1e4['avg_inference_time']:.3f}ì´ˆ ({results_1e4['avg_inference_time'] / results_base['avg_inference_time']:.2f}x)\n",
    "- 5e-4 ëª¨ë¸ í‰ê·  ì¶”ë¡  ì‹œê°„: {results_5e4['avg_inference_time']:.3f}ì´ˆ ({results_5e4['avg_inference_time'] / results_base['avg_inference_time']:.2f}x)\n",
    "\n",
    "ğŸ’¯ **ë³µì› í’ˆì§ˆ ë¶„ì„**\n",
    "- ì›ë³¸ ëª¨ë¸ ì™„ì „ ì¼ì¹˜: {match_analysis_base['perfect_match']}ê°œ ({match_analysis_base['perfect_match_rate']:.1%})\n",
    "- 1e-4 ëª¨ë¸ ì™„ì „ ì¼ì¹˜: {match_analysis_1e4['perfect_match']}ê°œ ({match_analysis_1e4['perfect_match_rate']:.1%})\n",
    "- 5e-4 ëª¨ë¸ ì™„ì „ ì¼ì¹˜: {match_analysis_5e4['perfect_match']}ê°œ ({match_analysis_5e4['perfect_match_rate']:.1%})\n",
    "\n",
    "ğŸ¯ **í•µì‹¬ ì¸ì‚¬ì´íŠ¸**\n",
    "1. ë¯¸ì„¸ì¡°ì •ì´ ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ ëª¨ë“  ì§€í‘œì—ì„œ í˜„ì €í•œ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì˜´\n",
    "2. {'5e-4 learning rateê°€ 1e-4ë³´ë‹¤ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„' if results_5e4['char_accuracy'] > results_1e4['char_accuracy'] else '1e-4 learning rateê°€ 5e-4ë³´ë‹¤ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„'}\n",
    "3. ì™„ì „ ì¼ì¹˜ìœ¨ì—ì„œ ê°€ì¥ ë“œë¼ë§ˆí‹±í•œ ê°œì„ ì„ í™•ì¸ (ì •í™•í•œ ë³µì› ëŠ¥ë ¥ í–¥ìƒ)\n",
    "4. ì¶”ë¡  ì‹œê°„ ì¦ê°€ëŠ” ë¯¸ë¯¸í•˜ì—¬ íš¨ìœ¨ì„± ì €í•˜ ì—†ì´ ì„±ëŠ¥ í–¥ìƒ ë‹¬ì„±\n",
    "5. ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ê¸¸ì´ì—ì„œ ì•ˆì •ì ì¸ ì„±ëŠ¥ í–¥ìƒ í™•ì¸\n",
    "\n",
    "ğŸ’¡ **ê¶Œì¥ ì‚¬í•­**\n",
    "- {'5e-4' if results_5e4['char_accuracy'] > results_1e4['char_accuracy'] else '1e-4'} learning rate ëª¨ë¸ ì‚¬ìš© ê°•ë ¥ ê¶Œì¥\n",
    "- ë” ë§ì€ ë°ì´í„°ë¡œ ì¶”ê°€ í•™ìŠµ ì‹œ ë” í° ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€ ê°€ëŠ¥\n",
    "- ì›ë³¸ ëª¨ë¸ì˜ ì œí•œì  ì„±ëŠ¥ì„ ê³ ë ¤í•  ë•Œ ë¯¸ì„¸ì¡°ì •ì˜ íš¨ê³¼ê°€ ë§¤ìš° ì˜ë¯¸ ìˆìŒ\n",
    "- Learning rate ìµœì í™”ë¥¼ í†µí•œ ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥ì„± íƒìƒ‰\n",
    "- ë„ë©”ì¸ íŠ¹í™” ì‘ì—…ì—ì„œ ë¯¸ì„¸ì¡°ì •ì˜ ì¤‘ìš”ì„± ì…ì¦\n",
    "\"\"\") \n",
    "\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd32b3",
   "metadata": {},
   "source": [
    "## 12. ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (3ê°œ ëª¨ë¸ ë¹„êµ)\n",
    "results_summary = pd.DataFrame({\n",
    "    'ëª¨ë¸': ['ì›ë³¸ ëª¨ë¸', '1e-4 Learning Rate ëª¨ë¸', '5e-4 Learning Rate ëª¨ë¸'],\n",
    "    'BLEU ì ìˆ˜': [results_base['bleu'], results_1e4['bleu'], results_5e4['bleu']],\n",
    "    'ROUGE-1': [results_base['rouge1'], results_1e4['rouge1'], results_5e4['rouge1']],\n",
    "    'ROUGE-2': [results_base['rouge2'], results_1e4['rouge2'], results_5e4['rouge2']],\n",
    "    'ROUGE-L': [results_base['rougeL'], results_1e4['rougeL'], results_5e4['rougeL']],\n",
    "    'ë¬¸ì ì •í™•ë„': [results_base['char_accuracy'], results_1e4['char_accuracy'], results_5e4['char_accuracy']],\n",
    "    'ì •í™• ì¼ì¹˜ìœ¨': [results_base['exact_match'], results_1e4['exact_match'], results_5e4['exact_match']],\n",
    "    'í‰ê·  ì¶”ë¡  ì‹œê°„': [results_base['avg_inference_time'], results_1e4['avg_inference_time'], results_5e4['avg_inference_time']],\n",
    "    'ì´ ì¶”ë¡  ì‹œê°„': [results_base['total_inference_time'], results_1e4['total_inference_time'], results_5e4['total_inference_time']]\n",
    "})\n",
    "\n",
    "# ìƒì„¸ ê²°ê³¼ë„ ì €ì¥ (3ê°œ ëª¨ë¸ í¬í•¨)\n",
    "detailed_results = pd.DataFrame({\n",
    "    'ì¸ë±ìŠ¤': range(len(results_base['predictions'])),\n",
    "    'ì›ë³¸': results_base['references'],\n",
    "    'ë‚œë…í™”': results_base['test_data']['obfuscated'].tolist(),\n",
    "    'ì˜ˆì¸¡_ì›ë³¸': results_base['predictions'],\n",
    "    'ì˜ˆì¸¡_1e4': results_1e4['predictions'],\n",
    "    'ì˜ˆì¸¡_5e4': results_5e4['predictions'],\n",
    "    'ë¬¸ì_ì •í™•ë„_ì›ë³¸': results_base['char_accuracies'],\n",
    "    'ë¬¸ì_ì •í™•ë„_1e4': results_1e4['char_accuracies'],\n",
    "    'ë¬¸ì_ì •í™•ë„_5e4': results_5e4['char_accuracies'],\n",
    "    'ì •í™•_ì¼ì¹˜_ì›ë³¸': results_base['exact_matches'],\n",
    "    'ì •í™•_ì¼ì¹˜_1e4': results_1e4['exact_matches'],\n",
    "    'ì •í™•_ì¼ì¹˜_5e4': results_5e4['exact_matches'],\n",
    "    'ì¶”ë¡ _ì‹œê°„_ì›ë³¸': results_base['inference_times'],\n",
    "    'ì¶”ë¡ _ì‹œê°„_1e4': results_1e4['inference_times'],\n",
    "    'ì¶”ë¡ _ì‹œê°„_5e4': results_5e4['inference_times']\n",
    "})\n",
    "\n",
    "# ë¯¸ì„¸ì¡°ì • íš¨ê³¼ ë¶„ì„ ê²°ê³¼ ì €ì¥\n",
    "finetuning_analysis = pd.DataFrame({\n",
    "    'ë¹„êµ': ['1e-4 vs ì›ë³¸', '5e-4 vs ì›ë³¸', '5e-4 vs 1e-4'],\n",
    "    'BLEU_ê°œì„ ìœ¨': [\n",
    "        ((results_1e4['bleu'] - results_base['bleu']) / results_base['bleu'] * 100) if results_base['bleu'] > 0 else 0,\n",
    "        ((results_5e4['bleu'] - results_base['bleu']) / results_base['bleu'] * 100) if results_base['bleu'] > 0 else 0,\n",
    "        ((results_5e4['bleu'] - results_1e4['bleu']) / results_1e4['bleu'] * 100) if results_1e4['bleu'] > 0 else 0\n",
    "    ],\n",
    "    'ë¬¸ìì •í™•ë„_ê°œì„ ìœ¨': [\n",
    "        ((results_1e4['char_accuracy'] - results_base['char_accuracy']) / results_base['char_accuracy'] * 100),\n",
    "        ((results_5e4['char_accuracy'] - results_base['char_accuracy']) / results_base['char_accuracy'] * 100),\n",
    "        ((results_5e4['char_accuracy'] - results_1e4['char_accuracy']) / results_1e4['char_accuracy'] * 100)\n",
    "    ],\n",
    "    'ì™„ì „ì¼ì¹˜ìœ¨_ê°œì„ ìœ¨': [\n",
    "        ((results_1e4['exact_match'] - results_base['exact_match']) / results_base['exact_match'] * 100) if results_base['exact_match'] > 0 else float('inf'),\n",
    "        ((results_5e4['exact_match'] - results_base['exact_match']) / results_base['exact_match'] * 100) if results_base['exact_match'] > 0 else float('inf'),\n",
    "        ((results_5e4['exact_match'] - results_1e4['exact_match']) / results_1e4['exact_match'] * 100) if results_1e4['exact_match'] > 0 else float('inf')\n",
    "    ],\n",
    "    'ì¶”ë¡ ì‹œê°„_ë¹„ìœ¨': [\n",
    "        results_1e4['avg_inference_time'] / results_base['avg_inference_time'],\n",
    "        results_5e4['avg_inference_time'] / results_base['avg_inference_time'],\n",
    "        results_5e4['avg_inference_time'] / results_1e4['avg_inference_time']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# CSV íŒŒì¼ ì €ì¥ ê²½ë¡œ (ë¶„ì„ ê²°ê³¼ í´ë” ë‚´)\n",
    "csv1_path = os.path.join(analysis_root_dir, 'model_performance_summary_with_base.csv')\n",
    "csv2_path = os.path.join(analysis_root_dir, 'detailed_model_comparison_with_base.csv')\n",
    "csv3_path = os.path.join(analysis_root_dir, 'finetuning_effect_analysis.csv')\n",
    "\n",
    "results_summary.to_csv(csv1_path, index=False, encoding='utf-8-sig')\n",
    "detailed_results.to_csv(csv2_path, index=False, encoding='utf-8-sig')\n",
    "finetuning_analysis.to_csv(csv3_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"ğŸ“ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(f\"- {csv1_path}\")\n",
    "print(f\"- {csv2_path}\")\n",
    "print(f\"- {csv3_path}\")\n",
    "\n",
    "# ì‹œê°í™” ì´ë¯¸ì§€ ëª©ë¡ ì¶œë ¥\n",
    "print(\"\\nğŸ“Š ìƒì„±ëœ ì‹œê°í™” ì´ë¯¸ì§€:\")\n",
    "image_files = os.listdir(image_save_dir)\n",
    "image_files = [f for f in image_files if f.endswith('.png')]\n",
    "for i, img_file in enumerate(sorted(image_files), 1):\n",
    "    print(f\"{i}. {os.path.join(image_save_dir, img_file)}\")\n",
    "\n",
    "# ê²°ê³¼ íŒŒì¼ë“¤ì„ ì••ì¶•í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„\n",
    "import zipfile\n",
    "zip_filename = os.path.join(analysis_root_dir, 'HyperCLOVAX_3Model_Analysis_Complete_Results.zip')\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "    # CSV íŒŒì¼ë“¤ ì¶”ê°€\n",
    "    zipf.write(csv1_path, 'results/model_performance_summary_with_base.csv')\n",
    "    zipf.write(csv2_path, 'results/detailed_model_comparison_with_base.csv')\n",
    "    zipf.write(csv3_path, 'results/finetuning_effect_analysis.csv')\n",
    "    \n",
    "    # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì¶”ê°€\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_save_dir, img_file)\n",
    "        zipf.write(img_path, f'visualizations/{img_file}')\n",
    "\n",
    "print(f\"\\nğŸ“¦ ì••ì¶• íŒŒì¼ ìƒì„±: {zip_filename}\")\n",
    "print(\"ì••ì¶• íŒŒì¼ ë‚´ìš©:\")\n",
    "print(\"  ğŸ“ results/ - CSV ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤ (3ê°œ ëª¨ë¸ ë¹„êµ)\")\n",
    "print(\"  ğŸ“ visualizations/ - ì‹œê°í™” ì´ë¯¸ì§€ë“¤ (3ê°œ ëª¨ë¸ ë¹„êµ)\")\n",
    "\n",
    "# Google Colabì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(zip_filename)\n",
    "    print(\"ğŸ“¥ ì••ì¶• íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’¾ ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ë‹¤ìŒ ê²½ë¡œì— ëª¨ë“  íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "    print(f\"   ë¶„ì„ ê²°ê³¼ í´ë”: {analysis_root_dir}\")\n",
    "    print(f\"   ì••ì¶• íŒŒì¼: {zip_filename}\")\n",
    "    print(f\"   ì´ë¯¸ì§€ í´ë”: {image_save_dir}\")\n",
    "\n",
    "# Google Drive í´ë” êµ¬ì¡° ì•ˆë‚´\n",
    "print(f\"\\nğŸ“‚ Google Drive í´ë” êµ¬ì¡°:\")\n",
    "print(f\"MyDrive/\")\n",
    "print(f\"â”œâ”€â”€ HyperCLOVAX_LearningRate_Analysis_Results/\")\n",
    "print(f\"â”‚   â”œâ”€â”€ model_performance_summary_with_base.csv      # 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½\")\n",
    "print(f\"â”‚   â”œâ”€â”€ detailed_model_comparison_with_base.csv      # 3ê°œ ëª¨ë¸ ìƒì„¸ ë¹„êµ\")\n",
    "print(f\"â”‚   â”œâ”€â”€ finetuning_effect_analysis.csv               # ë¯¸ì„¸ì¡°ì • íš¨ê³¼ ë¶„ì„\")\n",
    "print(f\"â”‚   â”œâ”€â”€ HyperCLOVAX_3Model_Analysis_Complete_Results.zip\")\n",
    "print(f\"â”‚   â””â”€â”€ visualization_images/\")\n",
    "print(f\"â”‚       â”œâ”€â”€ 01_model_performance_comparison.png      # 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\")\n",
    "print(f\"â”‚       â”œâ”€â”€ 02_character_accuracy_distribution.png\")\n",
    "print(f\"â”‚       â”œâ”€â”€ 03_inference_time_comparison.png\")\n",
    "print(f\"â”‚       â”œâ”€â”€ 04_performance_by_text_length.png\")\n",
    "print(f\"â”‚       â””â”€â”€ 05_accuracy_category_distribution.png\")\n",
    "print(f\"â”œâ”€â”€ hyperclova-deobfuscation-lora-1e-4-learning-rate/\")\n",
    "print(f\"â”œâ”€â”€ hyperclova-deobfuscation-lora-5e-4-learning-rate/\")\n",
    "print(f\"â””â”€â”€ testdata.csv\")\n",
    "\n",
    "# ê²°ê³¼ ìš”ì•½ ì¶œë ¥ (3ê°œ ëª¨ë¸)\n",
    "print(\"\\n=== ìµœì¢… ì„±ëŠ¥ ìš”ì•½ (ì›ë³¸ vs 1e-4 LR vs 5e-4 LR) ===\")\n",
    "print(results_summary.round(4))\n",
    "\n",
    "# ë¯¸ì„¸ì¡°ì • íš¨ê³¼ ìš”ì•½\n",
    "best_base_accuracy = results_base['char_accuracy']\n",
    "best_1e4_accuracy = results_1e4['char_accuracy']\n",
    "best_5e4_accuracy = results_5e4['char_accuracy']\n",
    "\n",
    "print(f\"\\n=== ë¯¸ì„¸ì¡°ì • íš¨ê³¼ ë¶„ì„ ===\")\n",
    "print(f\"ì›ë³¸ ëª¨ë¸ ë¬¸ì ì •í™•ë„: {best_base_accuracy:.4f}\")\n",
    "print(f\"1e-4 LR ëª¨ë¸ ë¬¸ì ì •í™•ë„: {best_1e4_accuracy:.4f} ({((best_1e4_accuracy - best_base_accuracy) / best_base_accuracy * 100):+.2f}%)\")\n",
    "print(f\"5e-4 LR ëª¨ë¸ ë¬¸ì ì •í™•ë„: {best_5e4_accuracy:.4f} ({((best_5e4_accuracy - best_base_accuracy) / best_base_accuracy * 100):+.2f}%)\")\n",
    "\n",
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì‹ë³„\n",
    "if best_5e4_accuracy > best_1e4_accuracy and best_5e4_accuracy > best_base_accuracy:\n",
    "    best_model = \"5e-4 Learning Rate\"\n",
    "    best_accuracy = best_5e4_accuracy\n",
    "elif best_1e4_accuracy > best_base_accuracy:\n",
    "    best_model = \"1e-4 Learning Rate\"\n",
    "    best_accuracy = best_1e4_accuracy\n",
    "else:\n",
    "    best_model = \"ì›ë³¸\"\n",
    "    best_accuracy = best_base_accuracy\n",
    "\n",
    "print(f\"\\nìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model} ëª¨ë¸ (ë¬¸ì ì •í™•ë„: {best_accuracy:.4f})\")\n",
    "\n",
    "if best_model != \"ì›ë³¸\":\n",
    "    improvement = ((best_accuracy - best_base_accuracy) / best_base_accuracy * 100)\n",
    "    print(f\"ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ: {improvement:.2f}%\")\n",
    "    print(f\"ë¯¸ì„¸ì¡°ì • íš¨ê³¼: {'ë§¤ìš° íš¨ê³¼ì ' if improvement > 20 else 'íš¨ê³¼ì ' if improvement > 10 else 'ë³´í†µ' if improvement > 5 else 'ì œí•œì '}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
