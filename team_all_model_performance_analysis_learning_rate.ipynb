{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bbf116",
   "metadata": {},
   "source": [
    "# 91veMe4Plus 팀 - 난독화 한국어 문자열 원본 추론 파인튜닝 모델 종합 성능 비교 분석\n",
    "\n",
    "이 노트북은 원본 HyperCLOVAX 모델, KoBART 원본 모델과 다양한 파라미터로 미세조정된 모델들의 성능을 종합적으로 비교하여 난독화된 한국어 문자열을 원본으로 복원하는 성능을 분석합니다.\n",
    "\n",
    "## 분석 목표\n",
    "- 모든 모델의 정량적 성능 비교 (BLEU, ROUGE, 문자 정확도)\n",
    "- 학습량(데이터셋 크기) 차이에 따른 난독화 해제 성능 비교\n",
    "- 학습률(Learning Rate) 차이에 따른 난독화 해제 성능 비교\n",
    "- 배치 크기(Batch Size) 차이에 따른 난독화 해제 성능 비교\n",
    "- 원본 모델 vs 파인튜닝 모델 성능 비교\n",
    "- 정성적 분석 (실제 출력 예시 비교)\n",
    "- 카테고리별 성능 분석\n",
    "- 추론 시간 및 효율성 비교\n",
    "- 파인튜닝 효과 종합 분석\n",
    "- 결과 시각화\n",
    "- **성능 결과 CSV 파일 추출**\n",
    "\n",
    "## 비교 모델 정보\n",
    "- **팀명**: 91veMe4Plus\n",
    "- **원본 모델들**:\n",
    "  - HyperCLOVAX 원본: `naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B`\n",
    "  - gogamza KoBART 원본: `gogamza/kobart-base-v2`\n",
    "  - hyunwoongko KoBART 원본: `hyunwoongko/kobart` (hyunwoongko KoBART 계열의 베이스 모델)\n",
    "- **HyperCLOVAX-0.5B 기반 파인튜닝 모델들**:\n",
    "  - **학습량 차이 파인튜닝 모델** (HyperCLOVAX-0.5B 기반):\n",
    "    - 10K 데이터셋 모델: `hyperclova-deobfuscation-lora-with-10k-datasets`\n",
    "    - 30K 데이터셋 모델: `hyperclova-deobfuscation-lora-with-30k-datasets`\n",
    "  - **학습률 차이 파인튜닝 모델** (HyperCLOVAX-0.5B 기반):\n",
    "    - 1e-4 Learning Rate 모델: `hyperclova-deobfuscation-lora-1e-4-learning-rate`\n",
    "    - 5e-4 Learning Rate 모델: `hyperclova-deobfuscation-lora-5e-4-learning-rate`\n",
    "  - **배치 크기 차이 파인튜닝 모델** (HyperCLOVAX-0.5B 기반):\n",
    "    - Batch Size 1 모델: `hyperclova-deobfuscation-lora-with-1-batch-size`\n",
    "    - Batch Size 2 모델: `hyperclova-deobfuscation-lora-with-2-batch-size`\n",
    "    - Batch Size 4 모델: `hyperclova-deobfuscation-lora-with-4-batch-size`\n",
    "- **KoBART 계열 파인튜닝 모델들**:\n",
    "  - hyunwoongko KoBART 기반: \n",
    "    - `hyunwoongko-kobart-25k` (25K 데이터로 파인튜닝)\n",
    "    - `hyunwoongko-kobart-2.5plus_1.6data` (데이터 변형 실험)\n",
    "    - `hyunwoongko-kobart-4.2data` (4.2 데이터 실험)\n",
    "    - `hyunwoongko-kobart-epochs-5` (5 에폭 실험)\n",
    "    - `hyunwoongko-kobart-learning-rate-1e-5` (1e-5 학습률 실험)\n",
    "  - gogamza KoBART 기반: `gogamza-kobart-hk-v1`, `gogamza-kobart-hk-v2` (gogamza/kobart-base-v2를 파인튜닝)\n",
    "- **테스트 데이터**: `testdata.csv` (1,002 샘플)\n",
    "- **분석 목적**: 난독화된 한국어 문자열을 원본으로 복원하는 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb29ec6",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bdfbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 확인\n",
    "!nvidia-smi\n",
    "\n",
    "# 필수 패키지 설치\n",
    "!pip install -q transformers\n",
    "!pip install -q peft\n",
    "!pip install -q torch\n",
    "!pip install -q datasets\n",
    "!pip install -q evaluate\n",
    "!pip install -q rouge-score\n",
    "!pip install -q sacrebleu\n",
    "!pip install -q sentencepiece\n",
    "!pip install -q protobuf\n",
    "!pip install -q matplotlib\n",
    "!pip install -q seaborn\n",
    "!pip install -q plotly\n",
    "!pip install -q pandas\n",
    "!pip install -q numpy\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q tqdm\n",
    "\n",
    "# KoBART 관련 추가 패키지\n",
    "!pip install -q tokenizers\n",
    "!pip install -q accelerate\n",
    "!pip install -q bitsandbytes\n",
    "\n",
    "print(\"패키지 설치 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58dc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib 및 seaborn 설정\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 이미지 저장 폴더 생성\n",
    "image_save_dir = '/content/drive/MyDrive/Colab Notebooks/analysis_images'\n",
    "os.makedirs(image_save_dir, exist_ok=True)\n",
    "print(f\"이미지 저장 폴더 생성: {image_save_dir}\")\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"사용 중인 장치: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5b03f",
   "metadata": {},
   "source": [
    "## 2. 데이터 로딩 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96487bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive 연결 (Colab에서 실행 시)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    import shutil\n",
    "    \n",
    "    # 기존 마운트 포인트가 있으면 정리\n",
    "    mount_point = '/content/drive'\n",
    "    if os.path.exists(mount_point):\n",
    "        try:\n",
    "            # 마운트 해제 시도\n",
    "            print(\"기존 마운트 포인트 정리 중...\")\n",
    "            os.system(f'fusermount -u {mount_point} 2>/dev/null || true')\n",
    "            shutil.rmtree(mount_point, ignore_errors=True)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Google Drive 마운트\n",
    "    drive.mount(mount_point, force_remount=True)\n",
    "    \n",
    "    # 경로 설정\n",
    "    BASE_PATH = '/content/drive/MyDrive/'\n",
    "    # 학습량 차이 모델\n",
    "    MODEL_10K_PATH = BASE_PATH + 'hyperclova-deobfuscation-lora-with-10k-datasets'\n",
    "    MODEL_30K_PATH = BASE_PATH + 'hyperclova-deobfuscation-lora-with-30k-datasets'\n",
    "    # 학습률 차이 모델\n",
    "    MODEL_1E4_PATH = BASE_PATH + 'hyperclova-deobfuscation-lora-1e-4-learning-rate'\n",
    "    MODEL_5E4_PATH = BASE_PATH + 'hyperclova-deobfuscation-lora-5e-4-learning-rate'\n",
    "    # 배치 크기 차이 모델\n",
    "    MODEL_BATCH1_PATH = BASE_PATH + 'hyperclova-deobfuscation-lora-with-1-batch-size'\n",
    "    MODEL_BATCH2_PATH = BASE_PATH + 'hyperclova-deobfuscation-lora-with-2-batch-size'\n",
    "    MODEL_BATCH4_PATH = BASE_PATH + 'hyperclova-deobfuscation-lora-with-4-batch-size'\n",
    "    # KoBART 모델들\n",
    "    KOBART_25K_PATH = BASE_PATH + 'hyunwoongko-kobart-25k'\n",
    "    KOBART_2_5PLUS_1_6DATA_PATH = BASE_PATH + 'hyunwoongko-kobart-2.5plus_1.6data'\n",
    "    KOBART_4_2DATA_PATH = BASE_PATH + 'hyunwoongko-kobart-4.2data'\n",
    "    KOBART_EPOCHS_5_PATH = BASE_PATH + 'hyunwoongko-kobart-epochs-5'\n",
    "    KOBART_LR_1E5_PATH = BASE_PATH + 'hyunwoongko-kobart-learning-rate-1e-5'\n",
    "    GOGAMZA_KOBART_HK_V1_PATH = BASE_PATH + 'gogamza-kobart-hk-v1'\n",
    "    GOGAMZA_KOBART_HK_V2_PATH = BASE_PATH + 'gogamza-kobart-hk-v2'\n",
    "    TEST_DATA_PATH = BASE_PATH + 'testdata.csv'\n",
    "    \n",
    "    # Google Drive 루트에 전용 분석 결과 폴더 생성\n",
    "    analysis_root_dir = os.path.join(BASE_PATH, 'HyperCLOVAX_Comprehensive_Analysis_Results')\n",
    "    os.makedirs(analysis_root_dir, exist_ok=True)\n",
    "    print(f\"분석 결과 루트 폴더 생성: {analysis_root_dir}\")\n",
    "    \n",
    "except ImportError:\n",
    "    # 로컬 실행 시\n",
    "    BASE_PATH = './'\n",
    "    # 학습량 차이 모델\n",
    "    MODEL_10K_PATH = './hyperclova-deobfuscation-lora-with-10k-datasets'\n",
    "    MODEL_30K_PATH = './hyperclova-deobfuscation-lora-with-30k-datasets'\n",
    "    # 학습률 차이 모델\n",
    "    MODEL_1E4_PATH = './hyperclova-deobfuscation-lora-1e-4-learning-rate'\n",
    "    MODEL_5E4_PATH = './hyperclova-deobfuscation-lora-5e-4-learning-rate'\n",
    "    # 배치 크기 차이 모델\n",
    "    MODEL_BATCH1_PATH = './hyperclova-deobfuscation-lora-with-1-batch-size'\n",
    "    MODEL_BATCH2_PATH = './hyperclova-deobfuscation-lora-with-2-batch-size'\n",
    "    MODEL_BATCH4_PATH = './hyperclova-deobfuscation-lora-with-4-batch-size'\n",
    "    # KoBART 모델들\n",
    "    KOBART_25K_PATH = './hyunwoongko-kobart-25k'\n",
    "    KOBART_2_5PLUS_1_6DATA_PATH = './hyunwoongko-kobart-2.5plus_1.6data'\n",
    "    KOBART_4_2DATA_PATH = './hyunwoongko-kobart-4.2data'\n",
    "    KOBART_EPOCHS_5_PATH = './hyunwoongko-kobart-epochs-5'\n",
    "    KOBART_LR_1E5_PATH = './hyunwoongko-kobart-learning-rate-1e-5'\n",
    "    GOGAMZA_KOBART_HK_V1_PATH = './gogamza-kobart-hk-v1'\n",
    "    GOGAMZA_KOBART_HK_V2_PATH = './gogamza-kobart-hk-v2'\n",
    "    TEST_DATA_PATH = './testdata.csv'\n",
    "    \n",
    "    # 로컬용 분석 결과 폴더\n",
    "    analysis_root_dir = './HyperCLOVAX_Comprehensive_Analysis_Results'\n",
    "    os.makedirs(analysis_root_dir, exist_ok=True)\n",
    "    print(f\"분석 결과 루트 폴더 생성: {analysis_root_dir}\")\n",
    "\n",
    "# 이미지 저장 폴더 생성 (분석 결과 폴더 내에)\n",
    "image_save_dir = os.path.join(analysis_root_dir, 'visualization_images')\n",
    "os.makedirs(image_save_dir, exist_ok=True)\n",
    "print(f\"이미지 저장 폴더 생성: {image_save_dir}\")\n",
    "\n",
    "# 모델 경로 딕셔너리 생성 (모든 키를 영어로 변경)\n",
    "MODEL_PATHS = {\n",
    "    # 원본 모델들 (HuggingFace에서 직접 로드)\n",
    "    'HyperCLOVAX_Original': \"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B\",\n",
    "    'gogamza_KoBART_Original': \"gogamza/kobart-base-v2\",\n",
    "    'hyunwoongko_KoBART_Original': \"hyunwoongko/kobart\",  # hyunwoongko KoBART 계열의 베이스 모델\n",
    "    # 학습량 차이 파인튜닝 모델\n",
    "    'HyperCLOVAX-0.5B_10K_Datasets': MODEL_10K_PATH,\n",
    "    'HyperCLOVAX-0.5B_30K_Datasets': MODEL_30K_PATH,\n",
    "    # 학습률 차이 파인튜닝 모델\n",
    "    'HyperCLOVAX-0.5B_1e4_LR': MODEL_1E4_PATH,\n",
    "    'HyperCLOVAX-0.5B_5e4_LR': MODEL_5E4_PATH,\n",
    "    # 배치 크기 차이 파인튜닝 모델\n",
    "    'HyperCLOVAX-0.5B_Batch1': MODEL_BATCH1_PATH,\n",
    "    'HyperCLOVAX-0.5B_Batch2': MODEL_BATCH2_PATH,\n",
    "    'HyperCLOVAX-0.5B_Batch4': MODEL_BATCH4_PATH,\n",
    "    # hyunwoongko KoBART 계열 파인튜닝 모델들\n",
    "    'hyunwoongko_KoBART_25K': KOBART_25K_PATH,  # hyunwoongko/kobart 기반\n",
    "    'hyunwoongko_KoBART_2_5plus_1_6data': KOBART_2_5PLUS_1_6DATA_PATH,  # 데이터 변형 실험\n",
    "    'hyunwoongko_KoBART_4_2data': KOBART_4_2DATA_PATH,  # 4.2 데이터 실험\n",
    "    'hyunwoongko_KoBART_epochs_5': KOBART_EPOCHS_5_PATH,  # 5 에폭 실험\n",
    "    'hyunwoongko_KoBART_LR_1e5': KOBART_LR_1E5_PATH,  # 1e-5 학습률 실험\n",
    "    # gogamza KoBART 계열 파인튜닝 모델들\n",
    "    'gogamza_KoBART_HK_v1': GOGAMZA_KOBART_HK_V1_PATH,  # gogamza/kobart-base-v2 기반\n",
    "    'gogamza_KoBART_HK_v2': GOGAMZA_KOBART_HK_V2_PATH   # gogamza/kobart-base-v2 기반\n",
    "}\n",
    "\n",
    "print(f\"\\n모든 모델 경로 설정 완료:\")\n",
    "for model_name, path in MODEL_PATHS.items():\n",
    "    print(f\"{model_name}: {path}\")\n",
    "print(f\"테스트 데이터 경로: {TEST_DATA_PATH}\")\n",
    "print(f\"분석 결과 저장 경로: {analysis_root_dir}\")\n",
    "print(f\"이미지 저장 경로: {image_save_dir}\")\n",
    "\n",
    "# 모델 존재 여부 확인 (로컬 파일만)\n",
    "print(\"\\n로컬 모델 존재 여부 확인:\")\n",
    "for model_name, path in MODEL_PATHS.items():\n",
    "    if not path.startswith(\"naver-\") and not path.startswith(\"gogamza/\") and not path.startswith(\"hyunwoongko/\"):\n",
    "        exists = os.path.exists(path)\n",
    "        print(f\"{model_name}: {'✓' if exists else '✗'} ({path})\")\n",
    "    else:\n",
    "        print(f\"{model_name}: HuggingFace Model ({path})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe95a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로드\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "print(f\"테스트 데이터 크기: {len(test_df)} 샘플\")\n",
    "print(f\"컬럼 목록: {test_df.columns.tolist()}\")\n",
    "print(\"\\n첫 5개 샘플:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# 데이터 통계\n",
    "print(\"\\n데이터 통계:\")\n",
    "print(f\"- 총 샘플 수: {len(test_df)}\")\n",
    "print(f\"- 원본 텍스트 평균 길이: {test_df['original'].str.len().mean():.1f}\")\n",
    "print(f\"- 난독화 텍스트 평균 길이: {test_df['obfuscated'].str.len().mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c660f8",
   "metadata": {},
   "source": [
    "## 3. 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e59ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 모델 이름들 설정\n",
    "HYPERCLOVA_MODEL_NAME = \"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B\"\n",
    "GOGAMZA_KOBART_MODEL_NAME = \"gogamza/kobart-base-v2\"\n",
    "HYUNWOONGKO_KOBART_MODEL_NAME = \"hyunwoongko/kobart\"\n",
    "\n",
    "# HyperCLOVAX 토크나이저 로드 (파인튜닝 모델에서)\n",
    "print(\"HyperCLOVAX 토크나이저 로딩 중...\")\n",
    "if os.path.exists(MODEL_1E4_PATH):\n",
    "    hyperclova_tokenizer = AutoTokenizer.from_pretrained(MODEL_1E4_PATH)\n",
    "    print(f\"HyperCLOVAX 토크나이저 어휘 크기: {len(hyperclova_tokenizer)}\")\n",
    "else:\n",
    "    # 원본 모델에서 토크나이저 로드\n",
    "    hyperclova_tokenizer = AutoTokenizer.from_pretrained(HYPERCLOVA_MODEL_NAME)\n",
    "    print(f\"HyperCLOVAX 원본 토크나이저 어휘 크기: {len(hyperclova_tokenizer)}\")\n",
    "\n",
    "# KoBART 토크나이저들 로드\n",
    "kobart_tokenizers = {}\n",
    "\n",
    "# gogamza KoBART 원본 토크나이저\n",
    "try:\n",
    "    print(\"gogamza KoBART 원본 토크나이저 로딩 중...\")\n",
    "    gogamza_kobart_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        GOGAMZA_KOBART_MODEL_NAME,\n",
    "        use_fast=False  # 한국어 처리를 위해 fast tokenizer 비활성화\n",
    "    )\n",
    "    kobart_tokenizers['gogamza_KoBART_Original'] = gogamza_kobart_tokenizer\n",
    "    print(f\"gogamza KoBART 원본 토크나이저 어휘 크기: {len(gogamza_kobart_tokenizer)}\")\n",
    "except Exception as e:\n",
    "    print(f\"gogamza KoBART 원본 토크나이저 로딩 실패: {e}\")\n",
    "\n",
    "# hyunwoongko KoBART 원본 토크나이저\n",
    "try:\n",
    "    print(\"hyunwoongko KoBART 원본 토크나이저 로딩 중...\")\n",
    "    hyunwoongko_kobart_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        HYUNWOONGKO_KOBART_MODEL_NAME,\n",
    "        use_fast=False  # 한국어 처리를 위해 fast tokenizer 비활성화\n",
    "    )\n",
    "    kobart_tokenizers['hyunwoongko_KoBART_Original'] = hyunwoongko_kobart_tokenizer\n",
    "    print(f\"hyunwoongko KoBART 원본 토크나이저 어휘 크기: {len(hyunwoongko_kobart_tokenizer)}\")\n",
    "except Exception as e:\n",
    "    print(f\"hyunwoongko KoBART 원본 토크나이저 로딩 실패: {e}\")\n",
    "\n",
    "# hyunwoongko KoBART-25K 토크나이저 (hyunwoongko/kobart 기반)\n",
    "if os.path.exists(KOBART_25K_PATH):\n",
    "    try:\n",
    "        print(\"hyunwoongko KoBART-25K 토크나이저 로딩 중...\")\n",
    "        kobart_25k_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            KOBART_25K_PATH,\n",
    "            use_fast=False,\n",
    "            local_files_only=True\n",
    "        )\n",
    "        kobart_tokenizers['hyunwoongko_KoBART_25K'] = kobart_25k_tokenizer\n",
    "        print(f\"hyunwoongko KoBART-25K 토크나이저 어휘 크기: {len(kobart_25k_tokenizer)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"hyunwoongko KoBART-25K 토크나이저 로딩 실패: {e}\")\n",
    "\n",
    "# gogamza-kobart-hk-v1 토크나이저 (gogamza/kobart-base-v2 기반)\n",
    "if os.path.exists(GOGAMZA_KOBART_HK_V1_PATH):\n",
    "    try:\n",
    "        print(\"gogamza KoBART-HK-v1 토크나이저 로딩 중...\")\n",
    "        v1_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            GOGAMZA_KOBART_HK_V1_PATH,\n",
    "            use_fast=False,\n",
    "            local_files_only=True\n",
    "        )\n",
    "        kobart_tokenizers['gogamza_KoBART_HK_v1'] = v1_tokenizer\n",
    "        print(f\"gogamza KoBART-HK-v1 토크나이저 어휘 크기: {len(v1_tokenizer)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"gogamza KoBART-HK-v1 토크나이저 로딩 실패: {e}\")\n",
    "\n",
    "# gogamza-kobart-hk-v2 토크나이저 (gogamza/kobart-base-v2 기반)\n",
    "if os.path.exists(GOGAMZA_KOBART_HK_V2_PATH):\n",
    "    try:\n",
    "        print(\"gogamza KoBART-HK-v2 토크나이저 로딩 중...\")\n",
    "        v2_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            GOGAMZA_KOBART_HK_V2_PATH,\n",
    "            use_fast=False,\n",
    "            local_files_only=True\n",
    "        )\n",
    "        kobart_tokenizers['gogamza_KoBART_HK_v2'] = v2_tokenizer\n",
    "        print(f\"gogamza KoBART-HK-v2 토크나이저 어휘 크기: {len(v2_tokenizer)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"gogamza KoBART-HK-v2 토크나이저 로딩 실패: {e}\")\n",
    "\n",
    "# 새로운 hyunwoongko KoBART 모델들의 토크나이저 로드\n",
    "additional_kobart_models = {\n",
    "    'hyunwoongko_KoBART_2_5plus_1_6data': KOBART_2_5PLUS_1_6DATA_PATH,\n",
    "    'hyunwoongko_KoBART_4_2data': KOBART_4_2DATA_PATH,\n",
    "    'hyunwoongko_KoBART_epochs_5': KOBART_EPOCHS_5_PATH,\n",
    "    'hyunwoongko_KoBART_LR_1e5': KOBART_LR_1E5_PATH\n",
    "}\n",
    "\n",
    "for model_key, model_path in additional_kobart_models.items():\n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            print(f\"{model_key} 토크나이저 로딩 중...\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_path,\n",
    "                use_fast=False,\n",
    "                local_files_only=True\n",
    "            )\n",
    "            kobart_tokenizers[model_key] = tokenizer\n",
    "            print(f\"{model_key} 토크나이저 어휘 크기: {len(tokenizer)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{model_key} 토크나이저 로딩 실패: {e}\")\n",
    "\n",
    "if not kobart_tokenizers:\n",
    "    print(\"KoBART 토크나이저를 로딩할 수 없습니다.\")\n",
    "else:\n",
    "    print(f\"총 {len(kobart_tokenizers)}개의 KoBART 토크나이저 로딩 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83913712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_finetuned_model(model_path, model_name, base_model_name):\n",
    "    \"\"\"파인튜닝된 LoRA 모델을 로드합니다\"\"\"\n",
    "    print(f\"\\n{model_name} 파인튜닝 모델 로딩 중...\")\n",
    "    \n",
    "    # 베이스 모델 로드\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # LoRA 어댑터 적용\n",
    "    model = PeftModel.from_pretrained(base_model, model_path)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"{model_name} 파인튜닝 모델 로딩 완료\")\n",
    "    return model\n",
    "\n",
    "def load_original_model(model_name, model_path):\n",
    "    \"\"\"원본 모델을 로드합니다\"\"\"\n",
    "    print(f\"\\n{model_name} 원본 모델 로딩 중...\")\n",
    "    \n",
    "    try:\n",
    "        # HyperCLOVAX 원본 모델\n",
    "        if 'HyperCLOVAX' in model_name:\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_path,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "        # KoBART 원본 모델\n",
    "        else:\n",
    "            from transformers import BartForConditionalGeneration\n",
    "            # KoBART는 Conditional Generation 모델로 로드\n",
    "            model = BartForConditionalGeneration.from_pretrained(\n",
    "                model_path,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\",\n",
    "                ignore_mismatched_sizes=True  # 크기 불일치 무시\n",
    "            )\n",
    "        \n",
    "        model = model.to(device)\n",
    "        print(f\"{model_name} 원본 모델 로딩 완료\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{model_name} 원본 모델 로딩 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_kobart_finetuned_model(model_path, model_name):\n",
    "    \"\"\"파인튜닝된 KoBART 모델을 로드합니다\"\"\"\n",
    "    print(f\"\\n{model_name} 파인튜닝 모델 로딩 중...\")\n",
    "    \n",
    "    try:\n",
    "        from transformers import BartForConditionalGeneration\n",
    "        \n",
    "        # KoBART 파인튜닝 모델은 항상 BartForConditionalGeneration으로 로드\n",
    "        model = BartForConditionalGeneration.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            ignore_mismatched_sizes=True,  # 크기 불일치 무시\n",
    "            force_download=False,\n",
    "            local_files_only=True  # 로컬 파일만 사용\n",
    "        )\n",
    "        \n",
    "        model = model.to(device)\n",
    "        print(f\"{model_name} 파인튜닝 모델 로딩 완료\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{model_name} 파인튜닝 모델 로딩 실패: {e}\")\n",
    "        # 대안으로 AutoModel 시도\n",
    "        try:\n",
    "            from transformers import AutoModel\n",
    "            model = AutoModel.from_pretrained(\n",
    "                model_path,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\",\n",
    "                ignore_mismatched_sizes=True\n",
    "            )\n",
    "            model = model.to(device)\n",
    "            print(f\"{model_name} 파인튜닝 모델 (AutoModel) 로딩 완료\")\n",
    "            return model\n",
    "        except Exception as e2:\n",
    "            print(f\"{model_name} 대안 로딩도 실패: {e2}\")\n",
    "            return None\n",
    "\n",
    "def load_selected_models():\n",
    "    \"\"\"선택된 모델들을 로딩합니다\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    # 메모리 효율성을 위해 일부 모델만 선택적으로 로드\n",
    "    selected_models = {\n",
    "        # 원본 모델들\n",
    "        'HyperCLOVAX_Original': HYPERCLOVA_MODEL_NAME,\n",
    "        'gogamza_KoBART_Original': GOGAMZA_KOBART_MODEL_NAME,\n",
    "        'hyunwoongko_KoBART_Original': HYUNWOONGKO_KOBART_MODEL_NAME,\n",
    "        # HyperCLOVAX 파인튜닝 모델들\n",
    "        'HyperCLOVAX-0.5B_1e4_LR': MODEL_1E4_PATH,\n",
    "        'HyperCLOVAX-0.5B_5e4_LR': MODEL_5E4_PATH,\n",
    "        'HyperCLOVAX-0.5B_10K_Datasets': MODEL_10K_PATH,\n",
    "        'HyperCLOVAX-0.5B_30K_Datasets': MODEL_30K_PATH,\n",
    "        'HyperCLOVAX-0.5B_Batch1': MODEL_BATCH1_PATH,\n",
    "        'HyperCLOVAX-0.5B_Batch4': MODEL_BATCH4_PATH,\n",
    "        # hyunwoongko KoBART 계열 파인튜닝 모델들\n",
    "        'hyunwoongko_KoBART_25K': KOBART_25K_PATH,  # hyunwoongko/kobart 기반\n",
    "        'hyunwoongko_KoBART_2_5plus_1_6data': KOBART_2_5PLUS_1_6DATA_PATH,  # 데이터 변형 실험\n",
    "        'hyunwoongko_KoBART_4_2data': KOBART_4_2DATA_PATH,  # 4.2 데이터 실험\n",
    "        'hyunwoongko_KoBART_epochs_5': KOBART_EPOCHS_5_PATH,  # 5 에폭 실험\n",
    "        'hyunwoongko_KoBART_LR_1e5': KOBART_LR_1E5_PATH,  # 1e-5 학습률 실험\n",
    "        # gogamza KoBART 계열 파인튜닝 모델들\n",
    "        'gogamza_KoBART_HK_v1': GOGAMZA_KOBART_HK_V1_PATH,  # gogamza/kobart-base-v2 기반\n",
    "        'gogamza_KoBART_HK_v2': GOGAMZA_KOBART_HK_V2_PATH   # gogamza/kobart-base-v2 기반\n",
    "    }\n",
    "    \n",
    "    for model_name, path in selected_models.items():\n",
    "        try:\n",
    "            if model_name in ['HyperCLOVAX_Original', 'gogamza_KoBART_Original', 'hyunwoongko_KoBART_Original']:\n",
    "                # 원본 모델 로드\n",
    "                model = load_original_model(model_name, path)\n",
    "                if model is not None:\n",
    "                    models[model_name] = model\n",
    "            elif 'HyperCLOVAX' in model_name:\n",
    "                # HyperCLOVAX 파인튜닝 모델 로드\n",
    "                if os.path.exists(path):\n",
    "                    models[model_name] = load_finetuned_model(path, model_name, HYPERCLOVA_MODEL_NAME)\n",
    "                else:\n",
    "                    print(f\"⚠️ {model_name} 경로가 존재하지 않습니다: {path}\")\n",
    "            elif 'KoBART' in model_name:\n",
    "                # KoBART 파인튜닝 모델 로드\n",
    "                if os.path.exists(path):\n",
    "                    model = load_kobart_finetuned_model(path, model_name)\n",
    "                    if model is not None:\n",
    "                        models[model_name] = model\n",
    "                else:\n",
    "                    print(f\"⚠️ {model_name} 경로가 존재하지 않습니다: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {model_name} 모델 로딩 실패: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n총 {len(models)}개 모델 로딩 완료!\")\n",
    "    return models\n",
    "\n",
    "# 모델 로드 실행\n",
    "print(\"모델 로딩을 시작합니다...\")\n",
    "loaded_models = load_selected_models()\n",
    "print(\"\\n로딩된 모델 목록:\")\n",
    "for model_name in loaded_models.keys():\n",
    "    print(f\"✓ {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212eb373",
   "metadata": {},
   "source": [
    "## 4. 추론 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_deobfuscated_text(model, obfuscated_text, model_name=\"\", max_length=256):\n",
    "    \"\"\"난독화된 텍스트를 원입력받아 원본 텍스트 생성\"\"\"\n",
    "    # KoBART 모델인 경우 다른 처리\n",
    "    if 'KoBART' in model_name:\n",
    "        return generate_deobfuscated_text_kobart(model, obfuscated_text, model_name, max_length)\n",
    "    \n",
    "    # HyperCLOVAX 모델 처리\n",
    "    prompt = f\"\"\"### 지시사항:\n",
    "다음 난독화된 한국어 텍스트를 원래 텍스트로 복원해주세요.\n",
    "\n",
    "난독화된 텍스트: {obfuscated_text}\n",
    "\n",
    "### 응답:\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = hyperclova_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_length,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=hyperclova_tokenizer.eos_token_id,\n",
    "            eos_token_id=hyperclova_tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    response = hyperclova_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 응답 부분만 추출\n",
    "    if \"### 응답:\" in response:\n",
    "        response = response.split(\"### 응답:\")[1].strip()\n",
    "        # 불필요한 부분 제거\n",
    "        if \"<|endoftext|>\" in response:\n",
    "            response = response.split(\"<|endoftext|>\")[0].strip()\n",
    "    \n",
    "    return response, inference_time\n",
    "\n",
    "def generate_deobfuscated_text_kobart(model, obfuscated_text, model_name, max_length=256):\n",
    "    \"\"\"KoBART 모델을 사용한 난독화 해제\"\"\"\n",
    "    # 해당 모델의 토크나이저 찾기\n",
    "    model_tokenizer = None\n",
    "    \n",
    "    if model_name in kobart_tokenizers:\n",
    "        model_tokenizer = kobart_tokenizers[model_name]\n",
    "    elif 'gogamza' in model_name and 'gogamza_KoBART_Original' in kobart_tokenizers:\n",
    "        # gogamza 계열 모델은 gogamza 원본 토크나이저 사용\n",
    "        model_tokenizer = kobart_tokenizers['gogamza_KoBART_Original']\n",
    "    elif 'hyunwoongko' in model_name and 'hyunwoongko_KoBART_Original' in kobart_tokenizers:\n",
    "        # hyunwoongko 계열 모델은 hyunwoongko 원본 토크나이저 사용\n",
    "        model_tokenizer = kobart_tokenizers['hyunwoongko_KoBART_Original']\n",
    "    \n",
    "    if model_tokenizer is None:\n",
    "        print(f\"⚠️ {model_name} 토크나이저가 로드되지 않았습니다.\")\n",
    "        return obfuscated_text, 0.0\n",
    "    \n",
    "    try:\n",
    "        # 특수 토큰 확인 및 설정\n",
    "        if model_tokenizer.pad_token is None:\n",
    "            model_tokenizer.pad_token = model_tokenizer.eos_token\n",
    "        \n",
    "        # BartForConditionalGeneration을 위한 입력 준비\n",
    "        if hasattr(model, 'generate') and 'BartForConditionalGeneration' in str(type(model)):\n",
    "            # Encoder-Decoder 모델의 경우\n",
    "            inputs = model_tokenizer(\n",
    "                obfuscated_text, \n",
    "                return_tensors=\"pt\", \n",
    "                truncation=True, \n",
    "                max_length=512,\n",
    "                padding=True\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # BartForConditionalGeneration을 위한 생성\n",
    "                outputs = model.generate(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    attention_mask=inputs.get('attention_mask'),\n",
    "                    max_length=max_length,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.9,\n",
    "                    num_beams=3,\n",
    "                    pad_token_id=model_tokenizer.pad_token_id,\n",
    "                    eos_token_id=model_tokenizer.eos_token_id,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "                \n",
    "            inference_time = time.time() - start_time\n",
    "            \n",
    "            # 입력 부분 제거하고 생성된 부분만 디코딩\n",
    "            generated_tokens = outputs[0]\n",
    "            response = model_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "            \n",
    "        else:\n",
    "            # 다른 아키텍처의 경우 기본 처리\n",
    "            inputs = model_tokenizer(\n",
    "                obfuscated_text, \n",
    "                return_tensors=\"pt\", \n",
    "                truncation=True, \n",
    "                max_length=512,\n",
    "                padding=True\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                if hasattr(model, 'generate'):\n",
    "                    outputs = model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=max_length,\n",
    "                        do_sample=True,\n",
    "                        temperature=0.7,\n",
    "                        top_p=0.9,\n",
    "                        pad_token_id=model_tokenizer.pad_token_id,\n",
    "                        eos_token_id=model_tokenizer.eos_token_id\n",
    "                    )\n",
    "                    response = model_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                else:\n",
    "                    # 생성 기능이 없는 경우 입력 반환\n",
    "                    response = obfuscated_text\n",
    "            \n",
    "            inference_time = time.time() - start_time\n",
    "        \n",
    "        return response.strip(), inference_time\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ {model_name} 추론 오류: {e}\")\n",
    "        return obfuscated_text, 0.0\n",
    "\n",
    "print(\"추론 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eaac22",
   "metadata": {},
   "source": [
    "## 5. 성능 평가 메트릭 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 메트릭 로드\n",
    "bleu = load(\"bleu\")\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "def calculate_character_accuracy(pred, ref):\n",
    "    \"\"\"문자 단위 정확도 계산\"\"\"\n",
    "    if len(ref) == 0:\n",
    "        return 1.0 if len(pred) == 0 else 0.0\n",
    "    \n",
    "    # 정확히 일치하는 문자 수 계산\n",
    "    matches = sum(1 for i, char in enumerate(pred) if i < len(ref) and char == ref[i])\n",
    "    return matches / len(ref)\n",
    "\n",
    "def calculate_exact_match(pred, ref):\n",
    "    \"\"\"완전 일치 여부\"\"\"\n",
    "    return 1.0 if pred.strip() == ref.strip() else 0.0\n",
    "\n",
    "def calculate_metrics(predictions, references):\n",
    "    \"\"\"모든 메트릭 계산\"\"\"\n",
    "    # BLEU 계산\n",
    "    try:\n",
    "        bleu_score = bleu.compute(predictions=predictions, references=[[ref] for ref in references])['bleu']\n",
    "    except:\n",
    "        bleu_score = 0.0\n",
    "    \n",
    "    # ROUGE 계산\n",
    "    try:\n",
    "        rouge_scores = rouge.compute(predictions=predictions, references=references)\n",
    "    except:\n",
    "        rouge_scores = {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
    "    \n",
    "    # 문자 정확도 계산\n",
    "    char_accuracies = [calculate_character_accuracy(pred, ref) for pred, ref in zip(predictions, references)]\n",
    "    avg_char_accuracy = np.mean(char_accuracies)\n",
    "    \n",
    "    # 완전 일치율 계산\n",
    "    exact_matches = [calculate_exact_match(pred, ref) for pred, ref in zip(predictions, references)]\n",
    "    exact_match_rate = np.mean(exact_matches)\n",
    "    \n",
    "    return {\n",
    "        'bleu': bleu_score,\n",
    "        'rouge1': rouge_scores['rouge1'],\n",
    "        'rouge2': rouge_scores['rouge2'],\n",
    "        'rougeL': rouge_scores['rougeL'],\n",
    "        'char_accuracy': avg_char_accuracy,\n",
    "        'exact_match': exact_match_rate,\n",
    "        'char_accuracies': char_accuracies,\n",
    "        'exact_matches': exact_matches\n",
    "    }\n",
    "\n",
    "print(\"평가 메트릭 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e3322",
   "metadata": {},
   "source": [
    "## 6. 모델 성능 평가 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, test_df, sample_size=None):\n",
    "    \"\"\"모델 성능 평가\"\"\"\n",
    "    if sample_size:\n",
    "        test_data = test_df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        test_data = test_df.copy()\n",
    "    \n",
    "    print(f\"\\n{model_name} 평가 시작 ({len(test_data)}개 샘플)\")\n",
    "    \n",
    "    predictions = []\n",
    "    inference_times = []\n",
    "    \n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data), desc=f\"{model_name} 평가\"):\n",
    "        obfuscated = row['obfuscated']\n",
    "        pred, inf_time = generate_deobfuscated_text(model, obfuscated, model_name)\n",
    "        predictions.append(pred)\n",
    "        inference_times.append(inf_time)\n",
    "    \n",
    "    # 참조 텍스트\n",
    "    references = test_data['original'].tolist()\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    metrics = calculate_metrics(predictions, references)\n",
    "    \n",
    "    # 추론 시간 통계\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    total_inference_time = np.sum(inference_times)\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'predictions': predictions,\n",
    "        'references': references,\n",
    "        'inference_times': inference_times,\n",
    "        'avg_inference_time': avg_inference_time,\n",
    "        'total_inference_time': total_inference_time,\n",
    "        'test_data': test_data,\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name} 평가 완료\")\n",
    "    print(f\"평균 추론 시간: {avg_inference_time:.3f}초\")\n",
    "    print(f\"총 추론 시간: {total_inference_time:.1f}초\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 모든 로딩된 모델에 대해 평가 실행\n",
    "SAMPLE_SIZE = 200  # 전체 평가를 원하면 None으로 설정\n",
    "\n",
    "print(\"모델 성능 평가를 시작합니다...\")\n",
    "\n",
    "# 모든 모델 결과 저장\n",
    "all_results = {}\n",
    "\n",
    "for model_name, model in loaded_models.items():\n",
    "    all_results[model_name] = evaluate_model(model, model_name, test_df, SAMPLE_SIZE)\n",
    "\n",
    "print(f\"\\n모든 모델 평가 완료! (총 {len(all_results)}개 모델)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18542a41",
   "metadata": {},
   "source": [
    "## 7. 종합 성능 비교 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델의 성능 비교 표 생성\n",
    "model_names = list(all_results.keys())\n",
    "metrics_to_show = ['bleu', 'rouge1', 'rouge2', 'rougeL', 'char_accuracy', 'exact_match', 'avg_inference_time']\n",
    "metric_labels = ['BLEU 점수', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L', '문자 정확도', '정확 일치율', '평균 추론 시간(초)']\n",
    "\n",
    "# 비교 표 데이터 준비\n",
    "comparison_data = {'Metric': metric_labels}\n",
    "for model_name in model_names:\n",
    "    model_values = []\n",
    "    for metric in metrics_to_show:\n",
    "        value = all_results[model_name][metric]\n",
    "        if metric == 'avg_inference_time':\n",
    "            model_values.append(f\"{value:.3f}\")\n",
    "        else:\n",
    "            model_values.append(f\"{value:.4f}\")\n",
    "    comparison_data[model_name] = model_values\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"=== 91veMe4Plus 팀 - 난독화 한국어 문자열 원본 추론 모델 성능 비교 결과 ===\")\n",
    "print(\"전체 모델 성능 비교 (원본 모델 vs 파인튜닝 모델들)\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# 원본 모델들과 파인튜닝 모델들 성능 비교\n",
    "original_models = ['HyperCLOVAX_Original', 'gogamza_KoBART_Original', 'hyunwoongko_KoBART_Original']\n",
    "finetuned_models = [name for name in model_names if name not in original_models]\n",
    "\n",
    "if original_models and finetuned_models:\n",
    "    print(\"\\n=== 원본 모델 대비 파인튜닝 모델 성능 개선율 ===\")\n",
    "    \n",
    "    # HyperCLOVAX 계열 비교\n",
    "    hyperclova_original = 'HyperCLOVAX_Original'\n",
    "    hyperclova_finetuned = [name for name in finetuned_models if 'HyperCLOVAX-0.5B' in name]\n",
    "    \n",
    "    if hyperclova_original in all_results and hyperclova_finetuned:\n",
    "        print(f\"\\n--- HyperCLOVAX-0.5B 계열 모델 비교 (vs {hyperclova_original}) ---\")\n",
    "        metrics_to_compare = ['bleu', 'rouge1', 'rouge2', 'rougeL', 'char_accuracy', 'exact_match']\n",
    "        \n",
    "        original_performance = all_results[hyperclova_original]\n",
    "        \n",
    "        for metric in metrics_to_compare:\n",
    "            print(f\"\\n{metric.upper()}:\")\n",
    "            original_value = original_performance[metric]\n",
    "            \n",
    "            for ft_model in hyperclova_finetuned:\n",
    "                ft_value = all_results[ft_model][metric]\n",
    "                if original_value > 0:\n",
    "                    improvement = ((ft_value - original_value) / original_value) * 100\n",
    "                    print(f\"  {ft_model}: {improvement:+7.2f}%\")\n",
    "                else:\n",
    "                    print(f\"  {ft_model}: N/A (original=0)\")\n",
    "    \n",
    "    # gogamza KoBART 계열 비교\n",
    "    gogamza_kobart_original = 'gogamza_KoBART_Original'\n",
    "    gogamza_kobart_finetuned = [name for name in finetuned_models if 'gogamza_KoBART' in name]\n",
    "    \n",
    "    if gogamza_kobart_original in all_results and gogamza_kobart_finetuned:\n",
    "        print(f\"\\n--- gogamza KoBART 계열 모델 비교 (vs {gogamza_kobart_original}) ---\")\n",
    "        \n",
    "        original_performance = all_results[gogamza_kobart_original]\n",
    "        \n",
    "        for metric in metrics_to_compare:\n",
    "            print(f\"\\n{metric.upper()}:\")\n",
    "            original_value = original_performance[metric]\n",
    "            \n",
    "            for ft_model in gogamza_kobart_finetuned:\n",
    "                ft_value = all_results[ft_model][metric]\n",
    "                if original_value > 0:\n",
    "                    improvement = ((ft_value - original_value) / original_value) * 100\n",
    "                    print(f\"  {ft_model}: {improvement:+7.2f}%\")\n",
    "                else:\n",
    "                    print(f\"  {ft_model}: N/A (original=0)\")\n",
    "    \n",
    "    # hyunwoongko KoBART 계열 비교\n",
    "    hyunwoongko_kobart_original = 'hyunwoongko_KoBART_Original'\n",
    "    hyunwoongko_kobart_finetuned = [name for name in finetuned_models if 'hyunwoongko_KoBART' in name]\n",
    "    \n",
    "    if hyunwoongko_kobart_original in all_results and hyunwoongko_kobart_finetuned:\n",
    "        print(f\"\\n--- hyunwoongko KoBART 계열 모델 비교 (vs {hyunwoongko_kobart_original}) ---\")\n",
    "        \n",
    "        original_performance = all_results[hyunwoongko_kobart_original]\n",
    "        \n",
    "        for metric in metrics_to_compare:\n",
    "            print(f\"\\n{metric.upper()}:\")\n",
    "            original_value = original_performance[metric]\n",
    "            \n",
    "            for ft_model in hyunwoongko_kobart_finetuned:\n",
    "                ft_value = all_results[ft_model][metric]\n",
    "                if original_value > 0:\n",
    "                    improvement = ((ft_value - original_value) / original_value) * 100\n",
    "                    print(f\"  {ft_model}: {improvement:+7.2f}%\")\n",
    "                else:\n",
    "                    print(f\"  {ft_model}: N/A (original=0)\")\n",
    "\n",
    "# 전체 최고 성능 모델 식별\n",
    "best_model_name = model_names[0]\n",
    "best_accuracy = all_results[model_names[0]]['char_accuracy']\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_accuracy = all_results[model_name]['char_accuracy']\n",
    "    if model_accuracy > best_accuracy:\n",
    "        best_accuracy = model_accuracy\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(f\"\\n=== 전반적 성능 요약 ===\")\n",
    "print(f\"가장 우수한 모델: {best_model_name} (문자 정확도: {best_accuracy:.4f})\")\n",
    "\n",
    "# 원본 모델과 최고 성능 모델 비교\n",
    "if 'Original' in best_model_name:\n",
    "    print(\"최고 성능 모델이 원본 모델입니다.\")\n",
    "else:\n",
    "    # 해당 계열의 원본 모델과 비교\n",
    "    if 'HyperCLOVAX-0.5B' in best_model_name and 'HyperCLOVAX_Original' in all_results:\n",
    "        original_accuracy = all_results['HyperCLOVAX_Original']['char_accuracy']\n",
    "        improvement = ((best_accuracy - original_accuracy) / original_accuracy * 100)\n",
    "        print(f\"HyperCLOVAX-0.5B 원본 모델 대비 성능 향상: {improvement:.2f}%\")\n",
    "    elif 'gogamza_KoBART' in best_model_name and 'gogamza_KoBART_Original' in all_results:\n",
    "        original_accuracy = all_results['gogamza_KoBART_Original']['char_accuracy']\n",
    "        improvement = ((best_accuracy - original_accuracy) / original_accuracy * 100)\n",
    "        print(f\"gogamza KoBART 원본 모델 대비 성능 향상: {improvement:.2f}%\")\n",
    "    elif 'hyunwoongko_KoBART' in best_model_name and 'hyunwoongko_KoBART_Original' in all_results:\n",
    "        original_accuracy = all_results['hyunwoongko_KoBART_Original']['char_accuracy']\n",
    "        improvement = ((best_accuracy - original_accuracy) / original_accuracy * 100)\n",
    "        print(f\"hyunwoongko KoBART 원본 모델 대비 성능 향상: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 모델 성능 비교 분석\n",
    "print(\"\\n=== All Models Performance Comparison ===\")\n",
    "\n",
    "# 1. 종합 성능 비교 차트 - 개별 이미지로 분리\n",
    "model_names_list = list(all_results.keys())\n",
    "n_models = len(model_names_list)\n",
    "\n",
    "# 색상 팔레트 생성 (모델 수에 따라 동적 조정)\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, n_models))\n",
    "\n",
    "metrics_data = {\n",
    "    'BLEU': [all_results[name]['bleu'] for name in model_names_list],\n",
    "    'ROUGE-1': [all_results[name]['rouge1'] for name in model_names_list],\n",
    "    'ROUGE-2': [all_results[name]['rouge2'] for name in model_names_list],\n",
    "    'ROUGE-L': [all_results[name]['rougeL'] for name in model_names_list],\n",
    "    'Character Accuracy': [all_results[name]['char_accuracy'] for name in model_names_list],\n",
    "    'Exact Match': [all_results[name]['exact_match'] for name in model_names_list]\n",
    "}\n",
    "\n",
    "# 각 메트릭별로 개별 이미지 생성\n",
    "for idx, (metric, values) in enumerate(metrics_data.items()):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "    \n",
    "    bars = ax.bar(range(n_models), values, color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax.set_title(f'{metric} Performance Comparison (Original vs Fine-tuned Models)', \n",
    "                 fontweight='bold', fontsize=14)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_xlabel('Models', fontsize=12)\n",
    "    ax.set_ylim(0, max(values) * 1.1 if max(values) > 0 else 1)\n",
    "    \n",
    "    # 모델 이름 라벨 (각도 조정)\n",
    "    ax.set_xticks(range(n_models))\n",
    "    ax.set_xticklabels([name.replace('_', '\\n') for name in model_names_list], \n",
    "                       rotation=45, ha='right', fontsize=10)\n",
    "    \n",
    "    # 값 표시\n",
    "    for bar, value in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,\n",
    "               f'{value:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # 그리드 추가\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 개별 이미지 저장\n",
    "    metric_safe_name = metric.replace('-', '_').replace(' ', '_').lower()\n",
    "    img_path = os.path.join(image_save_dir, f'01_{idx+1:02d}_{metric_safe_name}_comparison.png')\n",
    "    plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"이미지 저장: {img_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# 추가로 모든 메트릭을 한 번에 보여주는 종합 차트도 생성\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Comprehensive Model Performance Analysis (All Metrics)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (metric, values) in enumerate(metrics_data.items()):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    bars = axes[row, col].bar(range(n_models), values, color=colors, alpha=0.8, edgecolor='black')\n",
    "    axes[row, col].set_title(f'{metric}', fontweight='bold', fontsize=12)\n",
    "    axes[row, col].set_ylabel('Score')\n",
    "    axes[row, col].set_ylim(0, max(values) * 1.1 if max(values) > 0 else 1)\n",
    "    \n",
    "    # 모델 이름 라벨 (각도 조정)\n",
    "    axes[row, col].set_xticks(range(n_models))\n",
    "    axes[row, col].set_xticklabels([name.replace('_', '\\n') for name in model_names_list], \n",
    "                                   rotation=45, ha='right', fontsize=8)\n",
    "    \n",
    "    # 값 표시\n",
    "    for bar, value in zip(bars, values):\n",
    "        axes[row, col].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,\n",
    "                           f'{value:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "# 종합 이미지 저장\n",
    "img_path = os.path.join(image_save_dir, '01_00_comprehensive_performance_all_metrics.png')\n",
    "plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"종합 이미지 저장: {img_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문자 정확도 분포 비교\n",
    "n_models = len(model_names_list)\n",
    "fig, axes = plt.subplots(1, min(n_models, 4), figsize=(5*min(n_models, 4), 6))\n",
    "\n",
    "# 모델 수가 1개인 경우 axes를 리스트로 만들기\n",
    "if n_models == 1:\n",
    "    axes = [axes]\n",
    "elif n_models <= 4:\n",
    "    pass  # axes는 이미 리스트\n",
    "else:\n",
    "    # 4개 이상인 경우 첫 4개만 표시\n",
    "    model_names_list = model_names_list[:4]\n",
    "    n_models = 4\n",
    "\n",
    "colors_hist = ['lightgray', 'skyblue', 'lightcoral', 'lightgreen', 'plum', 'orange']\n",
    "\n",
    "for i, model_name in enumerate(model_names_list[:min(n_models, 4)]):\n",
    "    char_accuracies = all_results[model_name]['char_accuracies']\n",
    "    mean_accuracy = all_results[model_name]['char_accuracy']\n",
    "    \n",
    "    axes[i].hist(char_accuracies, bins=20, alpha=0.7, color=colors_hist[i % len(colors_hist)], edgecolor='black')\n",
    "    axes[i].set_title(f'{model_name}\\nCharacter Accuracy Distribution', fontweight='bold', fontsize=10)\n",
    "    axes[i].set_xlabel('Character Accuracy')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].axvline(mean_accuracy, color='red', linestyle='--', linewidth=2,\n",
    "                    label=f'Mean: {mean_accuracy:.3f}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# 이미지 저장\n",
    "img_path = os.path.join(image_save_dir, '02_character_accuracy_distribution.png')\n",
    "plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"이미지 저장: {img_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388bdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 추론 시간 비교\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 추론 시간 분포 비교 (Box Plot)\n",
    "inference_data = [all_results[name]['inference_times'] for name in model_names_list]\n",
    "labels = [name.replace('_', ' ') for name in model_names_list]\n",
    "\n",
    "box_plot = axes[0].boxplot(inference_data, labels=labels, patch_artist=True)\n",
    "\n",
    "# 박스 색상 설정\n",
    "for patch, color in zip(box_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "for median in box_plot['medians']:\n",
    "    median.set_color('red')\n",
    "    median.set_linewidth(2)\n",
    "\n",
    "axes[0].set_title('Inference Time Distribution Comparison', fontweight='bold')\n",
    "axes[0].set_ylabel('Inference Time (seconds)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 평균 추론 시간 막대 차트\n",
    "avg_times = [all_results[name]['avg_inference_time'] for name in model_names_list]\n",
    "bars = axes[1].bar(range(len(model_names_list)), avg_times, color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[1].set_title('Average Inference Time Comparison', fontweight='bold')\n",
    "axes[1].set_ylabel('Average Inference Time (seconds)')\n",
    "axes[1].set_xticks(range(len(model_names_list)))\n",
    "axes[1].set_xticklabels(labels, rotation=45, ha='right')\n",
    "\n",
    "# 값 표시\n",
    "for bar, time_val in zip(bars, avg_times):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(avg_times)*0.01,\n",
    "                f'{time_val:.3f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "# 이미지 저장\n",
    "img_path = os.path.join(image_save_dir, '03_inference_time_comparison.png')\n",
    "plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"이미지 저장: {img_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c6546",
   "metadata": {},
   "source": [
    "## 9. Qualitative Analysis - Example Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1944f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델 간 성능 차이가 큰 샘플들 찾기\n",
    "def find_performance_differences(all_results, n_samples=5):\n",
    "    \"\"\"모든 모델 간 성능 차이가 큰 샘플들 찾기\"\"\"\n",
    "    base_model_name = 'Base Model'  # 영어 키로 변경\n",
    "    \n",
    "    if base_model_name not in all_results:\n",
    "        print(\"Base model not available for performance difference analysis.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    base_accuracies = np.array(all_results[base_model_name]['char_accuracies'])\n",
    "    \n",
    "    # 가장 성능이 좋은 모델 찾기\n",
    "    best_model_name = base_model_name\n",
    "    best_overall_accuracy = np.mean(base_accuracies)\n",
    "    \n",
    "    for model_name in all_results.keys():\n",
    "        if model_name != base_model_name:\n",
    "            model_accuracy = all_results[model_name]['char_accuracy']\n",
    "            if model_accuracy > best_overall_accuracy:\n",
    "                best_overall_accuracy = model_accuracy\n",
    "                best_model_name = model_name\n",
    "    \n",
    "    if best_model_name == base_model_name:\n",
    "        print(\"Fine-tuned models do not outperform the base model.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    best_accuracies = np.array(all_results[best_model_name]['char_accuracies'])\n",
    "    \n",
    "    # 미세조정 효과가 가장 큰 인덱스\n",
    "    improvement = best_accuracies - base_accuracies\n",
    "    best_improvement_idx = np.argsort(improvement)[-n_samples:][::-1]\n",
    "    worst_improvement_idx = np.argsort(improvement)[:n_samples]\n",
    "    \n",
    "    return best_improvement_idx, worst_improvement_idx, best_model_name\n",
    "\n",
    "best_imp_idx, worst_imp_idx, best_model = find_performance_differences(all_results)\n",
    "\n",
    "if best_imp_idx is not None:\n",
    "    base_results = all_results['Base Model']  # 영어 키로 변경\n",
    "    best_results = all_results[best_model]\n",
    "    \n",
    "    print(f\"=== Most Effective Fine-tuning Examples ({best_model} vs Base Model) ===\")\n",
    "    for i, idx in enumerate(best_imp_idx):\n",
    "        print(f\"\\n[Example {i+1}]\")\n",
    "        print(f\"난독화 텍스트: {base_results['test_data'].iloc[idx]['obfuscated']}\")\n",
    "        print(f\"정답 텍스트: {base_results['references'][idx]}\")\n",
    "        print(f\"베이스 모델 예측: {base_results['predictions'][idx]}\")\n",
    "        print(f\"{best_model} 예측: {best_results['predictions'][idx]}\")\n",
    "        print(f\"Character Accuracy - Base: {base_results['char_accuracies'][idx]:.3f}, {best_model}: {best_results['char_accuracies'][idx]:.3f}\")\n",
    "        print(\"-\" * 120)\n",
    "    \n",
    "    print(f\"\\n=== Limited Fine-tuning Effect Examples ===\")\n",
    "    for i, idx in enumerate(worst_imp_idx):\n",
    "        print(f\"\\n[Example {i+1}]\")\n",
    "        print(f\"난독화 텍스트: {base_results['test_data'].iloc[idx]['obfuscated']}\")\n",
    "        print(f\"정답 텍스트: {base_results['references'][idx]}\")\n",
    "        print(f\"베이스 모델 예측: {base_results['predictions'][idx]}\")\n",
    "        print(f\"{best_model} 예측: {best_results['predictions'][idx]}\")\n",
    "        print(f\"Character Accuracy - Base: {base_results['char_accuracies'][idx]:.3f}, {best_model}: {best_results['char_accuracies'][idx]:.3f}\")\n",
    "        print(\"-\" * 120)\n",
    "    \n",
    "    # 전반적인 성능 비교 통계\n",
    "    print(\"\\n=== Overall Performance Comparison Statistics ===\")\n",
    "    base_char_acc = np.array(base_results['char_accuracies'])\n",
    "    best_char_acc = np.array(best_results['char_accuracies'])\n",
    "    \n",
    "    better_count = np.sum(best_char_acc > base_char_acc)\n",
    "    worse_count = np.sum(best_char_acc < base_char_acc)\n",
    "    tie_count = np.sum(best_char_acc == base_char_acc)\n",
    "    \n",
    "    print(f\"{best_model} > Base Model: {better_count} cases ({better_count/len(base_char_acc)*100:.1f}%)\")\n",
    "    print(f\"{best_model} < Base Model: {worse_count} cases ({worse_count/len(base_char_acc)*100:.1f}%)\")\n",
    "    print(f\"Ties: {tie_count} cases ({tie_count/len(base_char_acc)*100:.1f}%)\")\n",
    "    \n",
    "    avg_improvement = np.mean(best_char_acc - base_char_acc)\n",
    "    print(f\"\\nAverage performance improvement of {best_model} vs Base: {avg_improvement:.4f} ({avg_improvement*100:.2f}%p)\")\n",
    "else:\n",
    "    print(\"Performance difference analysis could not be performed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 카테고리별 비교 분석\n",
    "def categorize_models_updated(all_results):\n",
    "    \"\"\"모델들을 카테고리별로 분류 (업데이트된 버전)\"\"\"\n",
    "    categories = {\n",
    "        'Original Models': [],\n",
    "        'Learning Rate Variants': [],\n",
    "        'Dataset Size Variants': [],\n",
    "        'Batch Size Variants': [],\n",
    "        'gogamza KoBART Fine-tuned': [],\n",
    "        'hyunwoongko KoBART Fine-tuned': [],\n",
    "        'hyunwoongko KoBART Data Experiments': [],\n",
    "        'hyunwoongko KoBART Training Experiments': []\n",
    "    }\n",
    "    \n",
    "    for model_name in all_results.keys():\n",
    "        if 'Original' in model_name:\n",
    "            categories['Original Models'].append(model_name)\n",
    "        elif 'LR' in model_name and 'HyperCLOVAX' in model_name:\n",
    "            categories['Learning Rate Variants'].append(model_name)\n",
    "        elif 'Datasets' in model_name:\n",
    "            categories['Dataset Size Variants'].append(model_name)\n",
    "        elif 'Batch' in model_name:\n",
    "            categories['Batch Size Variants'].append(model_name)\n",
    "        elif 'gogamza_KoBART' in model_name and 'Original' not in model_name:\n",
    "            categories['gogamza KoBART Fine-tuned'].append(model_name)\n",
    "        elif 'hyunwoongko_KoBART' in model_name and 'Original' not in model_name:\n",
    "            # hyunwoongko KoBART 모델들을 세부 분류\n",
    "            if 'data' in model_name:\n",
    "                categories['hyunwoongko KoBART Data Experiments'].append(model_name)\n",
    "            elif 'epochs' in model_name or 'LR_1e5' in model_name:\n",
    "                categories['hyunwoongko KoBART Training Experiments'].append(model_name)\n",
    "            else:\n",
    "                categories['hyunwoongko KoBART Fine-tuned'].append(model_name)\n",
    "    \n",
    "    return categories\n",
    "\n",
    "# 카테고리별 성능 분석\n",
    "model_categories = categorize_models_updated(all_results)\n",
    "\n",
    "# 카테고리별 최고 성능 모델 식별\n",
    "print(\"=== Category-wise Performance Analysis ===\")\n",
    "for category, models in model_categories.items():\n",
    "    if models:\n",
    "        print(f\"\\n{category} Category:\")\n",
    "        best_model_in_category = None\n",
    "        best_accuracy_in_category = 0\n",
    "        \n",
    "        for model in models:\n",
    "            accuracy = all_results[model]['char_accuracy']\n",
    "            print(f\"  {model}: {accuracy:.4f}\")\n",
    "            \n",
    "            if accuracy > best_accuracy_in_category:\n",
    "                best_accuracy_in_category = accuracy\n",
    "                best_model_in_category = model\n",
    "        \n",
    "        if best_model_in_category:\n",
    "            print(f\"  → Best Performance: {best_model_in_category} ({best_accuracy_in_category:.4f})\")\n",
    "\n",
    "# 카테고리별 성능 비교 시각화\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "category_names = []\n",
    "category_scores = []\n",
    "category_colors = ['lightblue', 'lightcoral', 'lightgreen', 'plum', 'orange']\n",
    "\n",
    "for i, (category, models) in enumerate(model_categories.items()):\n",
    "    if models:\n",
    "        for model in models:\n",
    "            category_names.append(f\"{category}\\n{model.replace('_', ' ')}\")\n",
    "            category_scores.append(all_results[model]['char_accuracy'])\n",
    "\n",
    "bars = ax.bar(range(len(category_names)), category_scores, \n",
    "              color=[category_colors[i % len(category_colors)] for i in range(len(category_names))],\n",
    "              alpha=0.7, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Model Category')\n",
    "ax.set_ylabel('Character Accuracy')\n",
    "ax.set_title('Model Performance Comparison by Category', fontweight='bold')\n",
    "ax.set_xticks(range(len(category_names)))\n",
    "ax.set_xticklabels(category_names, rotation=45, ha='right', fontsize=8)\n",
    "\n",
    "# 값 표시\n",
    "for bar, score in zip(bars, category_scores):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "            f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "# 이미지 저장\n",
    "img_path = os.path.join(image_save_dir, '04_category_performance_comparison.png')\n",
    "plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"이미지 저장: {img_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"🔍 91veMe4Plus 팀 - 난독화 한국어 문자열 원본 추론 모델 종합 성능 분석 - 최종 결론\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# all_results 존재 여부 및 유효성 검사\n",
    "if 'all_results' not in globals() or all_results is None or not all_results:\n",
    "    print(\"\\n❌ **분석 결과가 없습니다.**\")\n",
    "    print(\"모델 평가가 아직 실행되지 않았거나 실패했습니다.\")\n",
    "    print(\"이전 셀들을 다시 실행해주세요.\")\n",
    "else:\n",
    "    model_names_list = list(all_results.keys())\n",
    "    \n",
    "    print(f\"\\n📊 **전체 모델 성능 분석 ({len(all_results)}개 모델 비교)**\\n\")\n",
    "    \n",
    "    # 원본 모델과 파인튜닝 모델 분리\n",
    "    original_models = [name for name in model_names_list if 'Original' in name]\n",
    "    finetuned_models = [name for name in model_names_list if 'Original' not in name]\n",
    "    \n",
    "    print(f\"원본 모델: {len(original_models)}개\")\n",
    "    for model in original_models:\n",
    "        accuracy = all_results[model]['char_accuracy']\n",
    "        print(f\"  • {model}: {accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"\\n파인튜닝 모델: {len(finetuned_models)}개\")\n",
    "    \n",
    "    # 최고 성능 모델들 찾기 (None 체크 포함)\n",
    "    best_models = {}\n",
    "    metrics = ['bleu', 'rouge1', 'rouge2', 'rougeL', 'char_accuracy', 'exact_match']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        best_score = 0\n",
    "        best_model = None\n",
    "        \n",
    "        for model_name in model_names_list:\n",
    "            try:\n",
    "                score = all_results[model_name][metric]\n",
    "                if score > best_score:\n",
    "                    best_score = score;\n",
    "                    best_model = model_name\n",
    "            except (KeyError, TypeError):\n",
    "                continue\n",
    "        \n",
    "        best_models[metric] = (best_model, best_score)\n",
    "    \n",
    "    # 메트릭별 최고 성능 모델 출력 (None 체크 포함)\n",
    "    print(\"\\n📈 **메트릭별 최고 성능 모델:**\")\n",
    "    for metric, (model, score) in best_models.items():\n",
    "        if model is not None:\n",
    "            model_type = \"Original\" if 'Original' in model else \"Fine-tuned\"\n",
    "            print(f\"  • {metric.upper()}: {model} ({model_type}, {score:.4f})\")\n",
    "        else:\n",
    "            print(f\"  • {metric.upper()}: 데이터 없음\")\n",
    "    \n",
    "    # 전반적 최고 성능 모델 (문자 정확도 기준)\n",
    "    if 'char_accuracy' in best_models and best_models['char_accuracy'][0] is not None:\n",
    "        overall_best_model, overall_best_score = best_models['char_accuracy']\n",
    "        \n",
    "        print(f\"\\n🏆 **전체 최고 성능 모델**: {overall_best_model}\")\n",
    "        print(f\"   Character Accuracy: {overall_best_score:.4f}\")\n",
    "        print(f\"   Model Type: {'Original' if 'Original' in overall_best_model else 'Fine-tuned'}\")\n",
    "        \n",
    "        # 파인튜닝 효과 분석\n",
    "        print(f\"\\n🎯 **파인튜닝 효과 분석:**\")\n",
    "        \n",
    "        # HyperCLOVAX 계열 분석\n",
    "        if 'HyperCLOVAX_Original' in all_results:\n",
    "            try:\n",
    "                hyperclova_original_score = all_results['HyperCLOVAX_Original']['char_accuracy']\n",
    "                hyperclova_finetuned = [name for name in finetuned_models if 'HyperCLOVAX-0.5B' in name]\n",
    "                \n",
    "                if hyperclova_finetuned:\n",
    "                    best_hyperclova_ft = max(hyperclova_finetuned, key=lambda x: all_results[x]['char_accuracy'])\n",
    "                    best_hyperclova_score = all_results[best_hyperclova_ft]['char_accuracy']\n",
    "                    if hyperclova_original_score > 0:\n",
    "                        hyperclova_improvement = ((best_hyperclova_score - hyperclova_original_score) / hyperclova_original_score * 100)\n",
    "                        \n",
    "                        print(f\"  • HyperCLOVAX-0.5B 계열:\")\n",
    "                        print(f\"    - 원본: {hyperclova_original_score:.4f}\")\n",
    "                        print(f\"    - 최고 파인튜닝: {best_hyperclova_ft} ({best_hyperclova_score:.4f})\")\n",
    "                        print(f\"    - 개선율: {hyperclova_improvement:+.2f}%\")\n",
    "            except (KeyError, TypeError) as e:\n",
    "                print(f\"  • HyperCLOVAX-0.5B 계열: 분석 실패 ({e})\")\n",
    "        \n",
    "        # gogamza KoBART 계열 분석\n",
    "        if 'gogamza_KoBART_Original' in all_results:\n",
    "            try:\n",
    "                gogamza_kobart_original_score = all_results['gogamza_KoBART_Original']['char_accuracy']\n",
    "                gogamza_kobart_finetuned = [name for name in finetuned_models if 'gogamza_KoBART' in name]\n",
    "                \n",
    "                if gogamza_kobart_finetuned:\n",
    "                    best_gogamza_kobart_ft = max(gogamza_kobart_finetuned, key=lambda x: all_results[x]['char_accuracy'])\n",
    "                    best_gogamza_kobart_score = all_results[best_gogamza_kobart_ft]['char_accuracy']\n",
    "                    if gogamza_kobart_original_score > 0:\n",
    "                        gogamza_kobart_improvement = ((best_gogamza_kobart_score - gogamza_kobart_original_score) / gogamza_kobart_original_score * 100)\n",
    "                        \n",
    "                        print(f\"  • gogamza KoBART 계열:\")\n",
    "                        print(f\"    - 원본: {gogamza_kobart_original_score:.4f}\")\n",
    "                        print(f\"    - 최고 파인튜닝: {best_gogamza_kobart_ft} ({best_gogamza_kobart_score:.4f})\")\n",
    "                        print(f\"    - 개선율: {gogamza_kobart_improvement:+.2f}%\")\n",
    "            except (KeyError, TypeError) as e:\n",
    "                print(f\"  • gogamza KoBART 계열: 분석 실패 ({e})\")\n",
    "        \n",
    "        # hyunwoongko KoBART 계열 분석\n",
    "        if 'hyunwoongko_KoBART_Original' in all_results:\n",
    "            try:\n",
    "                hyunwoongko_kobart_original_score = all_results['hyunwoongko_KoBART_Original']['char_accuracy']\n",
    "                hyunwoongko_kobart_finetuned = [name for name in finetuned_models if 'hyunwoongko_KoBART' in name]\n",
    "                \n",
    "                if hyunwoongko_kobart_finetuned:\n",
    "                    best_hyunwoongko_kobart_ft = max(hyunwoongko_kobart_finetuned, key=lambda x: all_results[x]['char_accuracy'])\n",
    "                    best_hyunwoongko_kobart_score = all_results[best_hyunwoongko_kobart_ft]['char_accuracy']\n",
    "                    if hyunwoongko_kobart_original_score > 0:\n",
    "                        hyunwoongko_kobart_improvement = ((best_hyunwoongko_kobart_score - hyunwoongko_kobart_original_score) / hyunwoongko_kobart_original_score * 100)\n",
    "                        \n",
    "                        print(f\"  • hyunwoongko KoBART 계열:\")\n",
    "                        print(f\"    - 원본: {hyunwoongko_kobart_original_score:.4f}\")\n",
    "                        print(f\"    - 최고 파인튜닝: {best_hyunwoongko_kobart_ft} ({best_hyunwoongko_kobart_score:.4f})\")\n",
    "                        print(f\"    - 개선율: {hyunwoongko_kobart_improvement:+.2f}%\")\n",
    "            except (KeyError, TypeError) as e:\n",
    "                print(f\"  • hyunwoongko KoBART 계열: 분석 실패 ({e})\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n⚠️ **최고 성능 모델을 찾을 수 없습니다.**\")\n",
    "    \n",
    "    # 카테고리별 성능 비교 시각화 (all_results가 유효할 때만)\n",
    "    if 'model_categories' in globals() and model_categories is not None:\n",
    "        try:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "            \n",
    "            category_names = []\n",
    "            category_scores = []\n",
    "            category_colors = ['lightblue', 'lightcoral', 'lightgreen', 'plum', 'orange']\n",
    "            \n",
    "            for i, (category, models) in enumerate(model_categories.items()):\n",
    "                if models:\n",
    "                    for model in models:\n",
    "                        if model in all_results and 'char_accuracy' in all_results[model]:\n",
    "                            category_names.append(f\"{category}\\n{model.replace('_', ' ')}\")\n",
    "                            category_scores.append(all_results[model]['char_accuracy'])\n",
    "            \n",
    "            if category_names and category_scores:\n",
    "                bars = ax.bar(range(len(category_names)), category_scores, \n",
    "                              color=[category_colors[i % len(category_colors)] for i in range(len(category_names))],\n",
    "                              alpha=0.7, edgecolor='black')\n",
    "                \n",
    "                ax.set_xlabel('Model Category')\n",
    "                ax.set_ylabel('Character Accuracy')\n",
    "                ax.set_title('Model Performance Comparison by Category', fontweight='bold')\n",
    "                ax.set_xticks(range(len(category_names)))\n",
    "                ax.set_xticklabels(category_names, rotation=45, ha='right', fontsize=8)\n",
    "                \n",
    "                # 값 표시\n",
    "                for bar, score in zip(bars, category_scores):\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                            f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=8)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                # 이미지 저장\n",
    "                img_path = os.path.join(image_save_dir, '05_final_category_performance_comparison.png')\n",
    "                plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "                print(f\"\\n📊 이미지 저장: {img_path}\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"\\n⚠️ 시각화할 카테고리 데이터가 없습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ 시각화 생성 중 오류 발생: {e}\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ 카테고리 분석 데이터가 없습니다.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"✅ 분석 완료!\")\n",
    "    print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754de3e",
   "metadata": {},
   "source": [
    "## 10. 성능 결과 CSV 파일 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd843d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 결과를 CSV 파일로 추출\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def export_performance_to_csv(all_results, analysis_root_dir):\n",
    "    \"\"\"성능 평가 결과를 CSV 파일로 저장\"\"\"\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"❌ 분석 결과가 없습니다. CSV 추출을 건너뜁니다.\")\n",
    "        return\n",
    "    \n",
    "    # CSV 저장 폴더 생성\n",
    "    csv_export_dir = os.path.join(analysis_root_dir, 'csv_exports')\n",
    "    os.makedirs(csv_export_dir, exist_ok=True)\n",
    "    \n",
    "    # 현재 시간 (파일명에 사용)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. 전체 모델 성능 요약 CSV\n",
    "    summary_csv_path = os.path.join(csv_export_dir, f'model_performance_summary_{timestamp}.csv')\n",
    "    \n",
    "    summary_data = []\n",
    "    metrics = ['bleu', 'rouge1', 'rouge2', 'rougeL', 'char_accuracy', 'exact_match', 'avg_inference_time', 'total_inference_time']\n",
    "    \n",
    "    for model_name in all_results.keys():\n",
    "        result = all_results[model_name]\n",
    "        row = {\n",
    "            'Model_Name': model_name,\n",
    "            'Model_Type': 'Original' if 'Original' in model_name else 'Fine-tuned',\n",
    "            'Model_Family': get_model_family(model_name),\n",
    "            'BLEU_Score': f\"{result['bleu']:.6f}\",\n",
    "            'ROUGE_1': f\"{result['rouge1']:.6f}\",\n",
    "            'ROUGE_2': f\"{result['rouge2']:.6f}\",\n",
    "            'ROUGE_L': f\"{result['rougeL']:.6f}\",\n",
    "            'Character_Accuracy': f\"{result['char_accuracy']:.6f}\",\n",
    "            'Exact_Match_Rate': f\"{result['exact_match']:.6f}\",\n",
    "            'Avg_Inference_Time_Sec': f\"{result['avg_inference_time']:.6f}\",\n",
    "            'Total_Inference_Time_Sec': f\"{result['total_inference_time']:.2f}\",\n",
    "            'Test_Samples': len(result['predictions']),\n",
    "            'Analysis_Date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        summary_data.append(row)\n",
    "    \n",
    "    # 문자 정확도로 정렬\n",
    "    summary_data.sort(key=lambda x: float(x['Character_Accuracy']), reverse=True)\n",
    "    \n",
    "    # CSV 저장\n",
    "    fieldnames = list(summary_data[0].keys())\n",
    "    with open(summary_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(summary_data)\n",
    "    \n",
    "    print(f\"✅ 전체 모델 성능 요약 CSV 저장: {summary_csv_path}\")\n",
    "    \n",
    "    # 2. 상세 예측 결과 CSV (샘플별)\n",
    "    detailed_csv_path = os.path.join(csv_export_dir, f'detailed_predictions_{timestamp}.csv')\n",
    "    \n",
    "    detailed_data = []\n",
    "    \n",
    "    # 각 모델의 예측 결과를 하나의 CSV로 통합\n",
    "    for model_name, result in all_results.items():\n",
    "        test_data = result['test_data']\n",
    "        predictions = result['predictions']\n",
    "        references = result['references']\n",
    "        char_accuracies = result['char_accuracies']\n",
    "        exact_matches = result['exact_matches']\n",
    "        inference_times = result['inference_times']\n",
    "        \n",
    "        for idx in range(len(predictions)):\n",
    "            row = {\n",
    "                'Sample_ID': idx + 1,\n",
    "                'Model_Name': model_name,\n",
    "                'Model_Type': 'Original' if 'Original' in model_name else 'Fine-tuned',\n",
    "                'Model_Family': get_model_family(model_name),\n",
    "                'Obfuscated_Text': test_data.iloc[idx]['obfuscated'] if hasattr(test_data, 'iloc') else test_data[idx]['obfuscated'],\n",
    "                'Reference_Text': references[idx],\n",
    "                'Predicted_Text': predictions[idx],\n",
    "                'Character_Accuracy': f\"{char_accuracies[idx]:.6f}\",\n",
    "                'Exact_Match': int(exact_matches[idx]),\n",
    "                'Inference_Time_Sec': f\"{inference_times[idx]:.6f}\",\n",
    "                'Analysis_Date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            detailed_data.append(row)\n",
    "    \n",
    "    # CSV 저장\n",
    "    detailed_fieldnames = list(detailed_data[0].keys()) if detailed_data else []\n",
    "    with open(detailed_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=detailed_fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(detailed_data)\n",
    "    \n",
    "    print(f\"✅ 상세 예측 결과 CSV 저장: {detailed_csv_path}\")\n",
    "    \n",
    "    # 3. 카테고리별 성능 비교 CSV\n",
    "    category_csv_path = os.path.join(csv_export_dir, f'category_performance_{timestamp}.csv')\n",
    "    \n",
    "    category_data = []\n",
    "    if 'model_categories' in globals() and model_categories:\n",
    "        for category, models in model_categories.items():\n",
    "            if models:\n",
    "                for model in models:\n",
    "                    if model in all_results:\n",
    "                        result = all_results[model]\n",
    "                        row = {\n",
    "                            'Category': category,\n",
    "                            'Model_Name': model,\n",
    "                            'BLEU_Score': f\"{result['bleu']:.6f}\",\n",
    "                            'ROUGE_1': f\"{result['rouge1']:.6f}\",\n",
    "                            'ROUGE_2': f\"{result['rouge2']:.6f}\",\n",
    "                            'ROUGE_L': f\"{result['rougeL']:.6f}\",\n",
    "                            'Character_Accuracy': f\"{result['char_accuracy']:.6f}\",\n",
    "                            'Exact_Match_Rate': f\"{result['exact_match']:.6f}\",\n",
    "                            'Avg_Inference_Time_Sec': f\"{result['avg_inference_time']:.6f}\",\n",
    "                            'Analysis_Date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        }\n",
    "                        category_data.append(row)\n",
    "        \n",
    "        # 카테고리별로 정렬\n",
    "        category_data.sort(key=lambda x: (x['Category'], -float(x['Character_Accuracy'])))\n",
    "        \n",
    "        # CSV 저장\n",
    "        category_fieldnames = list(category_data[0].keys()) if category_data else []\n",
    "        with open(category_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=category_fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(category_data)\n",
    "        \n",
    "        print(f\"✅ 카테고리별 성능 비교 CSV 저장: {category_csv_path}\")\n",
    "    \n",
    "    # 4. 최고 성능 모델 정보 CSV\n",
    "    best_models_csv_path = os.path.join(csv_export_dir, f'best_models_by_metric_{timestamp}.csv')\n",
    "    \n",
    "    best_models_data = []\n",
    "    metrics_for_best = ['bleu', 'rouge1', 'rouge2', 'rougeL', 'char_accuracy', 'exact_match']\n",
    "    \n",
    "    for metric in metrics_for_best:\n",
    "        best_score = 0\n",
    "        best_model = None\n",
    "        \n",
    "        for model_name in all_results.keys():\n",
    "            try:\n",
    "                score = all_results[model_name][metric]\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_model = model_name\n",
    "            except (KeyError, TypeError):\n",
    "                continue\n",
    "        \n",
    "        if best_model:\n",
    "            row = {\n",
    "                'Metric': metric.upper(),\n",
    "                'Best_Model': best_model,\n",
    "                'Best_Score': f\"{best_score:.6f}\",\n",
    "                'Model_Type': 'Original' if 'Original' in best_model else 'Fine-tuned',\n",
    "                'Model_Family': get_model_family(best_model),\n",
    "                'Analysis_Date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            best_models_data.append(row)\n",
    "    \n",
    "    # CSV 저장\n",
    "    best_models_fieldnames = list(best_models_data[0].keys()) if best_models_data else []\n",
    "    with open(best_models_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=best_models_fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(best_models_data)\n",
    "    \n",
    "    print(f\"✅ 최고 성능 모델 정보 CSV 저장: {best_models_csv_path}\")\n",
    "    \n",
    "    # 5. 모델 비교 개선율 CSV (원본 vs 파인튜닝)\n",
    "    improvement_csv_path = os.path.join(csv_export_dir, f'finetuning_improvement_{timestamp}.csv')\n",
    "    \n",
    "    improvement_data = []\n",
    "    metrics_for_improvement = ['bleu', 'rouge1', 'rouge2', 'rougeL', 'char_accuracy', 'exact_match']\n",
    "    \n",
    "    # HyperCLOVAX 계열 분석\n",
    "    if 'HyperCLOVAX_Original' in all_results:\n",
    "        hyperclova_original = all_results['HyperCLOVAX_Original']\n",
    "        hyperclova_finetuned = [name for name in all_results.keys() if 'HyperCLOVAX-0.5B' in name]\n",
    "        \n",
    "        for ft_model in hyperclova_finetuned:\n",
    "            ft_result = all_results[ft_model]\n",
    "            for metric in metrics_for_improvement:\n",
    "                original_score = hyperclova_original[metric]\n",
    "                ft_score = ft_result[metric]\n",
    "                \n",
    "                if original_score > 0:\n",
    "                    improvement_pct = ((ft_score - original_score) / original_score) * 100\n",
    "                else:\n",
    "                    improvement_pct = 0\n",
    "                \n",
    "                row = {\n",
    "                    'Model_Family': 'HyperCLOVAX',\n",
    "                    'Original_Model': 'HyperCLOVAX_Original',\n",
    "                    'Finetuned_Model': ft_model,\n",
    "                    'Metric': metric.upper(),\n",
    "                    'Original_Score': f\"{original_score:.6f}\",\n",
    "                    'Finetuned_Score': f\"{ft_score:.6f}\",\n",
    "                    'Improvement_Percentage': f\"{improvement_pct:.2f}\",\n",
    "                    'Analysis_Date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                improvement_data.append(row)\n",
    "    \n",
    "    # gogamza KoBART 계열 분석\n",
    "    if 'gogamza_KoBART_Original' in all_results:\n",
    "        gogamza_kobart_original = all_results['gogamza_KoBART_Original']\n",
    "        gogamza_kobart_finetuned = [name for name in all_results.keys() if 'gogamza_KoBART' in name and 'Original' not in name]\n",
    "        \n",
    "        for ft_model in gogamza_kobart_finetuned:\n",
    "            ft_result = all_results[ft_model]\n",
    "            for metric in metrics_for_improvement:\n",
    "                original_score = gogamza_kobart_original[metric]\n",
    "                ft_score = ft_result[metric]\n",
    "                \n",
    "                if original_score > 0:\n",
    "                    improvement_pct = ((ft_score - original_score) / original_score) * 100\n",
    "                else:\n",
    "                    improvement_pct = 0\n",
    "                \n",
    "                row = {\n",
    "                    'Model_Family': 'gogamza_KoBART',\n",
    "                    'Original_Model': 'gogamza_KoBART_Original',\n",
    "                    'Finetuned_Model': ft_model,\n",
    "                    'Metric': metric.upper(),\n",
    "                    'Original_Score': f\"{original_score:.6f}\",\n",
    "                    'Finetuned_Score': f\"{ft_score:.6f}\",\n",
    "                    'Improvement_Percentage': f\"{improvement_pct:.2f}\",\n",
    "                    'Analysis_Date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                improvement_data.append(row)\n",
    "    \n",
    "    # hyunwoongko KoBART 계열 분석\n",
    "    if 'hyunwoongko_KoBART_Original' in all_results:\n",
    "        hyunwoongko_kobart_original = all_results['hyunwoongko_KoBART_Original']\n",
    "        hyunwoongko_kobart_finetuned = [name for name in all_results.keys() if 'hyunwoongko_KoBART' in name and 'Original' not in name]\n",
    "        \n",
    "        for ft_model in hyunwoongko_kobart_finetuned:\n",
    "            ft_result = all_results[ft_model]\n",
    "            for metric in metrics_for_improvement:\n",
    "                original_score = hyunwoongko_kobart_original[metric]\n",
    "                ft_score = ft_result[metric]\n",
    "                \n",
    "                if original_score > 0:\n",
    "                    improvement_pct = ((ft_score - original_score) / original_score) * 100\n",
    "                else:\n",
    "                    improvement_pct = 0\n",
    "                \n",
    "                row = {\n",
    "                    'Model_Family': 'hyunwoongko_KoBART',\n",
    "                    'Original_Model': 'hyunwoongko_KoBART_Original',\n",
    "                    'Finetuned_Model': ft_model,\n",
    "                    'Metric': metric.upper(),\n",
    "                    'Original_Score': f\"{original_score:.6f}\",\n",
    "                    'Finetuned_Score': f\"{ft_score:.6f}\",\n",
    "                    'Improvement_Percentage': f\"{improvement_pct:.2f}\",\n",
    "                    'Analysis_Date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                improvement_data.append(row)\n",
    "    \n",
    "    # CSV 저장\n",
    "    if improvement_data:\n",
    "        improvement_fieldnames = list(improvement_data[0].keys())\n",
    "        with open(improvement_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=improvement_fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(improvement_data)\n",
    "        \n",
    "        print(f\"✅ 파인튜닝 개선율 CSV 저장: {improvement_csv_path}\")\n",
    "    \n",
    "    # 요약 정보 출력\n",
    "    print(f\"\\n📁 모든 CSV 파일이 저장된 폴더: {csv_export_dir}\")\n",
    "    print(\"\\n📊 생성된 CSV 파일 목록:\")\n",
    "    print(f\"  1. 전체 모델 성능 요약: {os.path.basename(summary_csv_path)}\")\n",
    "    print(f\"  2. 상세 예측 결과: {os.path.basename(detailed_csv_path)}\")\n",
    "    if category_data:\n",
    "        print(f\"  3. 카테고리별 성능 비교: {os.path.basename(category_csv_path)}\")\n",
    "    print(f\"  4. 최고 성능 모델 정보: {os.path.basename(best_models_csv_path)}\")\n",
    "    if improvement_data:\n",
    "        print(f\"  5. 파인튜닝 개선율: {os.path.basename(improvement_csv_path)}\")\n",
    "    \n",
    "    return csv_export_dir\n",
    "\n",
    "def get_model_family(model_name):\n",
    "    \"\"\"모델명에서 모델 패밀리 추출\"\"\"\n",
    "    if 'HyperCLOVAX' in model_name:\n",
    "        return 'HyperCLOVAX'\n",
    "    elif 'gogamza_KoBART' in model_name:\n",
    "        return 'gogamza_KoBART'\n",
    "    elif 'hyunwoongko_KoBART' in model_name:\n",
    "        return 'hyunwoongko_KoBART'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# CSV 추출 실행\n",
    "if 'all_results' in globals() and all_results:\n",
    "    print(\"📥 성능 평가 결과를 CSV 파일로 추출합니다...\")\n",
    "    csv_export_dir = export_performance_to_csv(all_results, analysis_root_dir)\n",
    "    \n",
    "    # 전체 모델 성능 요약을 데이터프레임으로도 표시\n",
    "    print(\"\\n📊 전체 모델 성능 요약 (상위 10개):\")\n",
    "    summary_df = pd.DataFrame([\n",
    "        {\n",
    "            'Model_Name': model_name,\n",
    "            'Model_Type': 'Original' if 'Original' in model_name else 'Fine-tuned',\n",
    "            'BLEU': f\"{result['bleu']:.4f}\",\n",
    "            'ROUGE-1': f\"{result['rouge1']:.4f}\",\n",
    "            'ROUGE-L': f\"{result['rougeL']:.4f}\",\n",
    "            'Char_Acc': f\"{result['char_accuracy']:.4f}\",\n",
    "            'Exact_Match': f\"{result['exact_match']:.4f}\",\n",
    "            'Avg_Time(s)': f\"{result['avg_inference_time']:.3f}\"\n",
    "        }\n",
    "        for model_name, result in all_results.items()\n",
    "    ])\n",
    "    \n",
    "    # 문자 정확도로 정렬\n",
    "    summary_df['Char_Acc_Float'] = summary_df['Char_Acc'].astype(float)\n",
    "    summary_df = summary_df.sort_values('Char_Acc_Float', ascending=False).drop('Char_Acc_Float', axis=1)\n",
    "    \n",
    "    print(summary_df.head(10).to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 분석 결과가 없어 CSV 추출을 수행할 수 없습니다.\")\n",
    "    print(\"이전 셀에서 모델 평가를 먼저 실행해주세요.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
