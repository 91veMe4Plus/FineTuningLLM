{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d49c53",
   "metadata": {},
   "source": [
    "# ğŸš€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ êµì • - ë¹ ë¥¸ ë°ëª¨ (Google Colab)\n",
    "\n",
    "ê¸°ì¡´ ëª¨ë¸ì„ í™œìš©í•œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ êµì • ë°ëª¨\n",
    "- ë¹ ë¥¸ ì„¤ì • ë° í…ŒìŠ¤íŠ¸\n",
    "- ì‚¬ì „ í›ˆë ¨ëœ mT5 ëª¨ë¸ í™œìš©\n",
    "- ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ êµì • ì²´í—˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84507e6",
   "metadata": {},
   "source": [
    "## âš¡ ë¹ ë¥¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU í™•ì¸ ë° ê¸°ë³¸ ì„¤ì •\n",
    "!nvidia-smi\n",
    "\n",
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install -q transformers torch gradio sentencepiece\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import gradio as gr\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828afc81",
   "metadata": {},
   "source": [
    "## ğŸ¤– ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24210bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ì „ í›ˆë ¨ëœ mT5 ëª¨ë¸ ë¡œë“œ (ë°ëª¨ìš©)\n",
    "print(\"ğŸ“¦ mT5 ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(\"âš ï¸  ì°¸ê³ : ì´ëŠ” ê¸°ë³¸ mT5 ëª¨ë¸ë¡œ, í•œêµ­ì–´ êµì •ì— íŠ¹í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "print(\"   ì‹¤ì œ ì„±ëŠ¥ì„ ìœ„í•´ì„œëŠ” colab_training.ipynbë¡œ íŒŒì¸íŠœë‹ì„ ì§„í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a57e92",
   "metadata": {},
   "source": [
    "## ğŸ”§ ë°ëª¨ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f382d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_correct_text(text: str) -> str:\n",
    "    \"\"\"ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ êµì • í•¨ìˆ˜ (ë°ëª¨ìš©)\"\"\"\n",
    "    if not text.strip():\n",
    "        return text\n",
    "    \n",
    "    # í•œêµ­ì–´ êµì •ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (ê¸°ë³¸ mT5 ëª¨ë¸ìš©)\n",
    "    input_text = f\"ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ì˜ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ êµì •í•˜ì„¸ìš”: {text.strip()}\"\n",
    "    \n",
    "    # í† í¬ë‚˜ì´ì œì´ì…˜\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ìƒì„±\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=256,\n",
    "            num_beams=3,\n",
    "            temperature=0.8,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            no_repeat_ngram_size=2\n",
    "        )\n",
    "    \n",
    "    # ê²°ê³¼ ë””ì½”ë”©\n",
    "    corrected = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return corrected.strip()\n",
    "\n",
    "def demo_correction_with_simple_rules(text: str) -> str:\n",
    "    \"\"\"ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ êµì •ê³¼ ëª¨ë¸ ê²°í•© (ë°ëª¨ìš©)\"\"\"\n",
    "    # ê¸°ë³¸ì ì¸ ê·œì¹™ ê¸°ë°˜ êµì •\n",
    "    simple_corrections = {\n",
    "        \"ì•ˆë…•í•˜ì…°ìš”\": \"ì•ˆë…•í•˜ì„¸ìš”\",\n",
    "        \"ê°ì‚¬í–ë‹ˆë‹¤\": \"ê°ì‚¬í•©ë‹ˆë‹¤\",\n",
    "        \"ê´œì± ìŠµë‹ˆê¹Œ\": \"ê´œì°®ìŠµë‹ˆê¹Œ\",\n",
    "        \"ì–´ë–»ê²Œ ìƒê°„í•˜ì„¸ìš”\": \"ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”\",\n",
    "        \"ë‚ ì‹œê°€\": \"ë‚ ì”¨ê°€\",\n",
    "        \"ë«ƒê² ìŠµë‹ˆë‹¤\": \"ë¶€íƒë“œë¦½ë‹ˆë‹¤\",\n",
    "        \"ì¡°ì„ê¹Œìš”\": \"ì¢‹ì„ê¹Œìš”\",\n",
    "        \"ì‹œì‘í•´ë‚˜ìš”\": \"ì‹œì‘í•©ë‹ˆê¹Œ\"\n",
    "    }\n",
    "    \n",
    "    # ê·œì¹™ ê¸°ë°˜ êµì • ë¨¼ì € ì ìš©\n",
    "    corrected_text = text\n",
    "    for wrong, correct in simple_corrections.items():\n",
    "        corrected_text = corrected_text.replace(wrong, correct)\n",
    "    \n",
    "    # ë³€ê²½ì´ ìˆì—ˆë‹¤ë©´ ê·œì¹™ ê¸°ë°˜ ê²°ê³¼ ë°˜í™˜\n",
    "    if corrected_text != text:\n",
    "        return corrected_text\n",
    "    \n",
    "    # ë³€ê²½ì´ ì—†ì—ˆë‹¤ë©´ ëª¨ë¸ ì‚¬ìš©\n",
    "    return simple_correct_text(text)\n",
    "\n",
    "print(\"âœ… êµì • í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e172d3",
   "metadata": {},
   "source": [
    "## ğŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab49dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤\n",
    "test_cases = [\n",
    "    \"ì•ˆë…•í•˜ì…°ìš”\",\n",
    "    \"ê°ì‚¬í–ë‹ˆë‹¤\", \n",
    "    \"ê´œì± ìŠµë‹ˆê¹Œ\",\n",
    "    \"ì–´ë–»ê²Œ ìƒê°„í•˜ì„¸ìš”\",\n",
    "    \"ì˜¤ëŠ˜ ë‚ ì‹œê°€ ì¢‹ë„¤ìš”\",\n",
    "    \"ì ì‹¬ ë©”ë‰´ëŠ” ë­ê°€ ì¡°ì„ê¹Œìš”\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª ë°ëª¨ í…ìŠ¤íŠ¸ êµì • í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, test_text in enumerate(test_cases, 1):\n",
    "    print(f\"\\n{i}. ì›ë³¸: {test_text}\")\n",
    "    \n",
    "    # ê·œì¹™ ê¸°ë°˜ + ëª¨ë¸ êµì •\n",
    "    start_time = time.time()\n",
    "    corrected = demo_correction_with_simple_rules(test_text)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"   êµì •: {corrected}\")\n",
    "    print(f\"   ì‹œê°„: {(end_time - start_time)*1000:.1f}ms\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29232b2",
   "metadata": {},
   "source": [
    "## ğŸ–¥ï¸ ëŒ€í™”í˜• ë°ëª¨ ì¸í„°í˜ì´ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6268c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradio_demo_correction(text, use_model):\n",
    "    \"\"\"Gradio ì¸í„°í˜ì´ìŠ¤ìš© êµì • í•¨ìˆ˜\"\"\"\n",
    "    if not text.strip():\n",
    "        return \"í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\", \"\"\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if use_model:\n",
    "            # ëª¨ë¸ ì‚¬ìš©\n",
    "            corrected = simple_correct_text(text)\n",
    "            method = \"mT5 ëª¨ë¸\"\n",
    "        else:\n",
    "            # ê·œì¹™ ê¸°ë°˜ + ëª¨ë¸ ì¡°í•©\n",
    "            corrected = demo_correction_with_simple_rules(text)\n",
    "            method = \"ê·œì¹™ ê¸°ë°˜ + ëª¨ë¸\"\n",
    "        \n",
    "        end_time = time.time()\n",
    "        info = f\"ë°©ë²•: {method} | ì²˜ë¦¬ ì‹œê°„: {(end_time - start_time)*1000:.1f}ms\"\n",
    "        \n",
    "        return corrected, info\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", \"\"\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤\n",
    "with gr.Blocks(title=\"í•œêµ­ì–´ í…ìŠ¤íŠ¸ êµì • ë°ëª¨\") as demo:\n",
    "    gr.Markdown(\"# ğŸ‡°ğŸ‡· í•œêµ­ì–´ í…ìŠ¤íŠ¸ êµì • ë°ëª¨\")\n",
    "    gr.Markdown(\n",
    "        \"ê¸°ë³¸ mT5 ëª¨ë¸ê³¼ ê°„ë‹¨í•œ ê·œì¹™ì„ í™œìš©í•œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ êµì • ë°ëª¨ì…ë‹ˆë‹¤.\\n\"\n",
    "        \"**ì°¸ê³ **: ë” ë‚˜ì€ ì„±ëŠ¥ì„ ìœ„í•´ì„œëŠ” í•œêµ­ì–´ ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_text = gr.Textbox(\n",
    "                label=\"êµì •í•  í…ìŠ¤íŠ¸\",\n",
    "                placeholder=\"êµì •í•˜ê³  ì‹¶ì€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...\",\n",
    "                lines=3\n",
    "            )\n",
    "            \n",
    "            use_model = gr.Checkbox(\n",
    "                value=False,\n",
    "                label=\"mT5 ëª¨ë¸ë§Œ ì‚¬ìš© (ì²´í¬ í•´ì œ ì‹œ ê·œì¹™ ê¸°ë°˜ + ëª¨ë¸ ì¡°í•© ì‚¬ìš©)\"\n",
    "            )\n",
    "            \n",
    "            correct_btn = gr.Button(\"êµì •í•˜ê¸°\", variant=\"primary\")\n",
    "            \n",
    "        with gr.Column():\n",
    "            output_text = gr.Textbox(\n",
    "                label=\"êµì •ëœ í…ìŠ¤íŠ¸\",\n",
    "                lines=3\n",
    "            )\n",
    "            processing_info = gr.Textbox(\n",
    "                label=\"ì²˜ë¦¬ ì •ë³´\",\n",
    "                lines=1\n",
    "            )\n",
    "    \n",
    "    # ì˜ˆì‹œ\n",
    "    gr.Markdown(\"### ğŸ“ ì˜ˆì‹œ í…ìŠ¤íŠ¸ (í´ë¦­í•´ì„œ í…ŒìŠ¤íŠ¸)\")\n",
    "    examples = gr.Examples(\n",
    "        examples=[\n",
    "            [\"ì•ˆë…•í•˜ì…°ìš”\"],\n",
    "            [\"ê°ì‚¬í–ë‹ˆë‹¤\"],\n",
    "            [\"ê´œì± ìŠµë‹ˆê¹Œ\"],\n",
    "            [\"ì–´ë–»ê²Œ ìƒê°„í•˜ì„¸ìš”\"],\n",
    "            [\"ì˜¤ëŠ˜ ë‚ ì‹œê°€ ì •ë§ ì¢‹ë„¤ìš”\"],\n",
    "            [\"ì ì‹¬ ë©”ë‰´ëŠ” ë­ê°€ ì¡°ì„ê¹Œìš”\"]\n",
    "        ],\n",
    "        inputs=[input_text]\n",
    "    )\n",
    "    \n",
    "    # ì‚¬ìš©ë²• ì•ˆë‚´\n",
    "    gr.Markdown(\n",
    "        \"### ğŸ’¡ ì‚¬ìš©ë²•\\n\"\n",
    "        \"1. **ê·œì¹™ ê¸°ë°˜ + ëª¨ë¸**: ì¼ë°˜ì ì¸ ì˜¤íƒ€ëŠ” ê·œì¹™ìœ¼ë¡œ, ë³µì¡í•œ ê²½ìš°ëŠ” ëª¨ë¸ë¡œ ì²˜ë¦¬\\n\"\n",
    "        \"2. **mT5 ëª¨ë¸ë§Œ**: ìˆœìˆ˜í•˜ê²Œ mT5 ëª¨ë¸ë§Œ ì‚¬ìš© (ë” ëŠë¦¬ì§€ë§Œ ë‹¤ì–‘í•œ ì¼€ì´ìŠ¤ ì²˜ë¦¬ ê°€ëŠ¥)\\n\"\n",
    "        \"3. **ë” ë‚˜ì€ ì„±ëŠ¥**: `colab_training.ipynb`ë¡œ í•œêµ­ì–´ ë°ì´í„°ì— íŠ¹í™”ëœ ëª¨ë¸ í›ˆë ¨ ê¶Œì¥\"\n",
    "    )\n",
    "    \n",
    "    # ì´ë²¤íŠ¸ ì—°ê²°\n",
    "    correct_btn.click(\n",
    "        fn=gradio_demo_correction,\n",
    "        inputs=[input_text, use_model],\n",
    "        outputs=[output_text, processing_info]\n",
    "    )\n",
    "\n",
    "# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "print(\"ğŸ–¥ï¸ Gradio ë°ëª¨ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff122e2c",
   "metadata": {},
   "source": [
    "## ğŸ“Š ì„±ëŠ¥ ì°¸ê³ ì‚¬í•­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸\n",
    "print(\"âš¡ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_text = \"ì•ˆë…•í•˜ì…°ìš”. ì˜¤ëŠ˜ ë‚ ì‹œê°€ ì •ë§ ì¢‹ë„¤ìš”!\"\n",
    "\n",
    "# ê·œì¹™ ê¸°ë°˜ + ëª¨ë¸\n",
    "times_rule = []\n",
    "for _ in range(5):\n",
    "    start = time.time()\n",
    "    result_rule = demo_correction_with_simple_rules(test_text)\n",
    "    times_rule.append(time.time() - start)\n",
    "\n",
    "# ëª¨ë¸ë§Œ\n",
    "times_model = []\n",
    "for _ in range(5):\n",
    "    start = time.time()\n",
    "    result_model = simple_correct_text(test_text)\n",
    "    times_model.append(time.time() - start)\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸: {test_text}\")\n",
    "print(f\"\\nğŸ“Š ì„±ëŠ¥ ë¹„êµ:\")\n",
    "print(f\"ê·œì¹™ ê¸°ë°˜ + ëª¨ë¸:\")\n",
    "print(f\"  - ê²°ê³¼: {result_rule}\")\n",
    "print(f\"  - í‰ê·  ì‹œê°„: {np.mean(times_rule)*1000:.1f}ms\")\n",
    "print(f\"\\nmT5 ëª¨ë¸ë§Œ:\")\n",
    "print(f\"  - ê²°ê³¼: {result_model}\")\n",
    "print(f\"  - í‰ê·  ì‹œê°„: {np.mean(times_model)*1000:.1f}ms\")\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf27ec",
   "metadata": {},
   "source": [
    "## ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ ë°ëª¨ëŠ” ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ êµì • ê¸°ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë” ë‚˜ì€ ì„±ëŠ¥ì„ ìœ„í•´ì„œëŠ”:\n",
    "\n",
    "### 1. ğŸ“š ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸\n",
    "- `colab_training.ipynb` ë…¸íŠ¸ë¶ì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ ë°ì´í„°ë¡œ ëª¨ë¸ íŒŒì¸íŠœë‹\n",
    "- LoRAë¥¼ í™œìš©í•œ íš¨ìœ¨ì ì¸ íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "- ë‹¤ì–‘í•œ ë„ë©”ì¸ì˜ í•œêµ­ì–´ ë°ì´í„° í™œìš©\n",
    "\n",
    "### 2. ğŸ” ì „ìš© ì¶”ë¡  ì‹œìŠ¤í…œ\n",
    "- `colab_inference.ipynb` ë…¸íŠ¸ë¶ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° ì •ëŸ‰ì  í‰ê°€\n",
    "- ë°°ì¹˜ ì²˜ë¦¬ ë° ìµœì í™”ëœ ì¶”ë¡ \n",
    "\n",
    "### 3. ğŸ¯ ì‹¤ì œ ì ìš©\n",
    "- íŠ¹ì • ë„ë©”ì¸(ë‰´ìŠ¤, êµ¬ì–´ì²´, ë¬¸ì–´ì²´ ë“±)ì— íŠ¹í™”ëœ ëª¨ë¸ í›ˆë ¨\n",
    "- API ì„œë²„ êµ¬ì¶• ë° í”„ë¡œë•ì…˜ ë°°í¬\n",
    "- ì§€ì†ì ì¸ ëª¨ë¸ ê°œì„  ë° ì—…ë°ì´íŠ¸\n",
    "\n",
    "### ğŸ“ íŒŒì¼ êµ¬ì¡°\n",
    "```\n",
    "ğŸ“ FineTuningLLM/\n",
    "â”œâ”€â”€ ğŸ§ª colab_demo.ipynb       â† í˜„ì¬ ë°ëª¨ (ê¸°ë³¸ í…ŒìŠ¤íŠ¸)\n",
    "â”œâ”€â”€ ğŸš€ colab_training.ipynb   â† ëª¨ë¸ í›ˆë ¨ (T4 GPU ìµœì í™”)\n",
    "â””â”€â”€ ğŸ” colab_inference.ipynb  â† ëª¨ë¸ ì¶”ë¡  ë° í‰ê°€\n",
    "```\n",
    "\n",
    "**ì‹œì‘ ìˆœì„œ**: ë°ëª¨ â†’ í›ˆë ¨ â†’ ì¶”ë¡  ìˆœìœ¼ë¡œ ì§„í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤! ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
